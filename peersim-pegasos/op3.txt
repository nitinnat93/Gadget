


network.node
model file and train file are saved in: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters
Number of nodes is ####### 10
creating node with ID: 0
getTrainingData

Objective Value after gossip/before training: 1
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_0.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_0.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_0.dat
Objective Value after training: 9707.98
WeightVector: 
 407:-5470.35 1694:-4160.56 1809:-6186.91 2175:-7729.69 4431:-5921.83 5329:-6792.04 5752:-7299.81 5880:-8498.57 5894:-9661.5 6036:-5886.9 6632:-6344.17 7706:-22401.4 7791:-21581.5 8021:-3808.93
pred0.dat = predicted labels file
118.775 = avg Loss of solution
(222/330) = number of misclassified examples

creating node with ID: 1
getTrainingData

Objective Value after gossip/before training: 1
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_1.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_1.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_1.dat
Objective Value after training: 11233.3
WeightVector: 
 48:4155.13 59:1666.19 87:3345.21 300:1743.28 494:2874.18 521:3463.17 523:2631.5 564:1736.97 589:1927.53 642:1825.72 677:2028.43 871:9112.8 895:3141.36 1008:2201.94 1019:3161.18 1077:1681.65 1097:3466.11 1114:1640.46 1161:1511.91 1239:2520.82 1371:3660.12 1518:2448.71 1673:3572.95 1826:4054.32 1827:1230.93 1909:1851.48 1910:5556.42 1924:1604.55 2007:2206.2 2180:7681.16 2192:855.296 2205:4346.49 2208:2930.36 2263:1807.11 2279:3146.63 2310:1756.13 2341:2799.28 2534:2514.53 2572:2671.06 2577:1301.96 2597:1807.64 2656:1483.11 2716:2773.06 2763:1622.22 2769:5145.34 2816:2300.0 2819:2671.06 2855:4654.26 2907:3248.81 2935:3717.29 2940:4997.77 2982:4784.75 2996:1456.67 3088:3709.31 3161:2938.46 3259:753.952 3275:1772.62 3376:1791.33 3415:1680.23 3462:1491.19 3505:3041.81 3537:3038.92 3654:1070.03 3780:1315.21 3809:5372.1 3810:2986.83 3812:4513.24 3898:5251.55 4010:4809.09 4154:3325.13 4269:12087.0 4295:2174.68 4324:2317.27 4362:4946.08 4441:2408.23 4453:3745.55 4461:2018.0 4483:1800.34 4498:3337.13 4501:3057.77 4724:1966.23 4820:1904.36 4821:2439.07 4844:3889.38 4954:1694.61 5009:3889.38 5258:2450.05 5295:2527.14 5326:2141.6 5370:2184.99 5387:2490.25 5395:2023.19 5430:1951.34 5464:2820.23 5615:3317.39 5625:1827.01 5657:5093.58 5663:1865.11 5785:2740.74 5858:3099.93 5958:1259.9 6036:2450.84 6039:2687.69 6235:1340.35 6450:878.55 6459:1017.94 6499:2820.23 6502:3245.1 6582:4126.57 6586:1807.11 6587:4330.89 6596:1428.68 6638:1803.56 6659:861.255 6714:1670.37 6734:3964.88 6766:1534.51 6891:1685.94 6978:3201.59 6996:2609.03 7058:3343.69 7086:2831.77 7166:2098.32 7189:2335.08 7250:2779.09 7443:2462.94 7486:3088.12 7517:3006.49 7523:5041.37 7549:1240.64 7573:1089.68 7576:1975.73 7595:2527.14 7611:4121.42 7648:4592.75 7662:7248.88 7758:3430.85 7793:1140.39 8027:738.967 8097:1253.85 8271:899.976 8276:3361.57 8279:4939.01 8281:1903.83
pred1.dat = predicted labels file
1684.18 = avg Loss of solution
(330/330) = number of misclassified examples

creating node with ID: 2
getTrainingData

Objective Value after gossip/before training: 1
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_2.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_2.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_2.dat
Objective Value after training: 9700.82
WeightVector: 
 567:-15849.6 1809:-11762.2 2701:-17615.9 4762:-7422.4 5881:-9909.44 6253:-11099.1 6720:-15078.5 8021:-17279.9
pred2.dat = predicted labels file
0.342424 = avg Loss of solution
(113/330) = number of misclassified examples

creating node with ID: 3
getTrainingData

Objective Value after gossip/before training: 1
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_3.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_3.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_3.dat
Objective Value after training: 9786.32
WeightVector: 
 86:-2006.3 138:-2247.01 254:-1996.02 300:-1892.98 526:-3454.18 557:-2177.43 564:-1886.12 958:-2448.71 969:-6889.86 971:-2909.39 1008:-1412.18 1114:-1781.32 1237:-3299.88 1404:-1659.16 1463:-4825.58 1480:-2058.22 1529:-3692.26 1643:-1511.18 1725:-1529.03 1926:-4417.82 2112:-3299.88 2192:-928.741 2370:-3334.97 2616:-4395.3 2622:-3162.87 2656:-1610.47 2753:-1730.3 3259:-818.694 3438:-2399.57 3505:-4093.99 3549:-6124.77 3609:-3028.6 3633:-3728.18 3690:-1233.58 4023:-10242.7 4024:-9035.26 4046:-3007.05 4142:-4511.94 4146:-1972.02 4148:-2114.94 4155:-2298.21 4227:-3879.76 4251:-5451.98 4288:-2801.98 4338:-1896.44 4339:-2614.08 4435:-4318.38 4441:-1544.48 4501:-2262.78 4762:-841.014 4797:-4648.95 4800:-2660.44 4851:-3097.03 4900:-9312.5 5147:-1387.46 5191:-1713.34 5219:-2217.06 5256:-3925.27 5335:-12867.2 5336:-12109.3 5430:-719.27 5818:-1862.7 5888:-2946.61 6131:-3476.51 6179:-2787.0 6224:-2259.42 6450:-638.58 6514:-3028.6 6574:-1972.02 6586:-1962.29 6685:-4511.94 6707:-3619.33 6714:-1813.8 6817:-2372.62 6891:-4368.61 6986:-3797.78 7030:-1433.02 7246:-2996.56 7256:-4669.87 7319:-1581.76 7362:-12337.1 7415:-2477.24 7443:-1274.38 7499:-2672.89 7524:-2270.22 7539:-2625.34 7573:-2003.43 7619:-2608.52 7793:-1238.31 7893:-3235.19 7946:-2097.85 8027:-802.423 8233:-3523.76 8235:-2361.42 8277:-1800.31
pred3.dat = predicted labels file
0.0818182 = avg Loss of solution
(27/330) = number of misclassified examples

creating node with ID: 4
getTrainingData

Objective Value after gossip/before training: 1
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_4.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_4.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_4.dat
Objective Value after training: 9715.37
WeightVector: 
 59:-3613.18 146:-5595.65 147:-12389.8 300:-3780.35 876:-5349.6 1516:-1637.36 1533:-3408.81 1616:-6813.53 1743:-17921.0 2082:-5828.32 2192:-1095.43 2279:-3251.46 2314:-3278.6 2546:-3888.29 2576:-5301.03 2597:-3919.92 3259:-1634.96 3618:-4760.98 3661:-2478.9 3791:-4704.23 3812:-4101.36 5201:-3993.59 5310:-5984.23 5430:-1436.41 5776:-4070.43 5843:-7037.09 6235:-2906.57 6329:-10134.0 6387:-6855.1 6450:-1275.27 6459:-4632.55 6596:-3098.12 6748:-4942.35 6817:-4738.2 6839:-6556.38 6893:-10102.5 7163:-3560.25 7575:-8289.79 7765:-4933.5 7793:-2472.95 7898:-5792.26 7913:-3595.28 8229:-5757.22
pred4.dat = predicted labels file
0.148485 = avg Loss of solution
(49/330) = number of misclassified examples

creating node with ID: 5
getTrainingData

Objective Value after gossip/before training: 1
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_5.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_5.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_5.dat
Objective Value after training: 9703.61
WeightVector: 
 567:-12865.8 1694:-3792.2 1809:-6989.58 2054:-7321.3 2192:-2320.95 2447:-9066.64 3892:-7806.17 4748:-17564.0 4762:-6941.11 4770:-19670.7 5881:-4750.88 6253:-9009.64 6720:-10188.5 8021:-10690.9 8271:-2442.19
pred5.dat = predicted labels file
0.181818 = avg Loss of solution
(60/330) = number of misclassified examples

creating node with ID: 6
getTrainingData

Objective Value after gossip/before training: 1
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_6.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_6.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_6.dat
Objective Value after training: 9715.23
WeightVector: 
 567:-10516.3 1809:-5948.22 2092:-16452.5 2192:-4445.46 2496:-5878.74 2581:-4727.88 2627:-5377.28 2996:-3881.53 3654:-4827.61 3656:-4810.59 3690:-3027.12 3810:-3792.44 4353:-2849.98 4762:-3753.56 4861:-10115.4 5066:-2644.78 5201:-8538.16 5742:-16831.3 5881:-6574.99 6253:-7364.33 6582:-3938.69 6720:-7625.29 7820:-11841.6 8021:-7595.88 8125:-6019.47 8271:-1416.37
pred6.dat = predicted labels file
0.169697 = avg Loss of solution
(56/330) = number of misclassified examples

creating node with ID: 7
getTrainingData

Objective Value after gossip/before training: 1
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_7.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_7.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_7.dat
Objective Value after training: 9725.11
WeightVector: 
 1809:-6910.33 2192:-4815.55 2701:-10349.4 2838:-12263.3 3080:-18536.3 4762:-7190.15 5066:-5588.27 5881:-9857.22 6253:-11040.6 6720:-8858.65 8021:-12532.8 8097:-16846.1 8271:-2992.72
pred7.dat = predicted labels file
0.254545 = avg Loss of solution
(84/330) = number of misclassified examples

creating node with ID: 8
getTrainingData

Objective Value after gossip/before training: 1
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_8.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_8.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_8.dat
Objective Value after training: 9781.25
WeightVector: 
 149:-6147.73 165:-4949.62 373:-6733.26 407:-2497.71 1438:-11235.5 1462:-8049.76 1505:-3499.39 1626:-4451.7 1629:-6994.41 1643:-5423.29 1712:-4989.67 1965:-11603.3 2135:-4467.17 2534:-3418.17 2570:-6793.8 2616:-2913.86 2990:-3948.16 3213:-6092.34 3217:-2792.4 3296:-6566.89 3436:-7577.47 3456:-8798.54 3791:-2948.91 3846:-3534.36 4010:-5274.27 4602:-5450.04 4612:-4167.47 5225:-5128.51 5607:-6857.29 5768:-3368.2 5801:-3451.0 5806:-5172.33 5915:-13102.1 5978:-4179.88 6236:-6186.01 6450:-1190.35 6624:-4406.39 6937:-5395.42 7298:-3489.56 7323:-6564.44 7443:-2701.18 7457:-3543.51 7499:-3346.1 8027:-1700.81 8224:-4095.37
pred8.dat = predicted labels file
0.527273 = avg Loss of solution
(174/330) = number of misclassified examples

creating node with ID: 9
getTrainingData

Objective Value after gossip/before training: 1
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_9.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_9.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_9.dat
Objective Value after training: 9805.54
WeightVector: 
 75:-4313.95 285:-7932.97 494:-4789.33 642:-9726.78 1008:-3669.17 1297:-15362.0 1477:-6265.6 1533:-4435.01 1694:-2328.65 2192:-1425.21 2394:-12538.0 2828:-13184.8 4472:-5456.96 4624:-8182.81 4762:-1290.58 4918:-9827.84 5054:-6097.52 5374:-16243.0 6450:-695.295 7030:-3723.32 7170:-10785.4 7793:-5447.56
pred9.dat = predicted labels file
0.0759878 = avg Loss of solution
(25/329) = number of misclassified examples

Entering next cycle.
Norm: 38759.69848019461 Node ID: 0
getTrainingData
Loading modelfile
Objective Value after gossip/before training: 9707.98
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_0.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_0.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_0.dat
Objective Value after training: 2431.71
WeightVector before pushsum: 
 407:-2735.18 1694:-2080.28 1809:-3093.45 2175:-3864.84 4431:-2960.91 5329:-3396.02 5752:-3649.91 5880:-4249.28 5894:-4830.75 6036:-2943.45 6632:-3172.09 7706:-11200.7 7791:-10790.8 8021:-1904.46
Node 0 is gossiping with Node 9....
WeightVector after pushsum: 
 75:-2156.975 285:-3966.485 407:-2735.18 494:-2394.665 642:-4863.39 1008:-1834.585 1297:-7681.0 1477:-3132.8 1533:-2217.505 1694:-2204.465 1809:-3093.45 2175:-3864.84 2192:-712.605 2394:-6269.0 2828:-6592.4 4431:-2960.91 4472:-2728.48 4624:-4091.405 4762:-645.29 4918:-4913.92 5054:-3048.76 5329:-3396.02 5374:-8121.5 5752:-3649.91 5880:-4249.28 5894:-4830.75 6036:-2943.45 6450:-347.6475 6632:-3172.09 7030:-1861.66 7170:-5392.7 7706:-11200.7 7791:-10790.8 7793:-2723.78 8021:-1904.46
current node ID: [0]
pred0.dat = predicted labels file
59.7239 = avg Loss of solution
(222/330) = number of misclassified examples

Printing out global weights after this round of gossip.
[finish]: global weight norm at node[0]: 27392.244613770814
[finish]: global weight norm at node[1]: 38759.69566596092
[finish]: global weight norm at node[2]: 38759.69880886073
[finish]: global weight norm at node[3]: 38759.66890314651
[finish]: global weight norm at node[4]: 38759.7030136455
[finish]: global weight norm at node[5]: 38759.66325820697
[finish]: global weight norm at node[6]: 38759.67044943623
[finish]: global weight norm at node[7]: 38759.72232132346
[finish]: global weight norm at node[8]: 38759.722676992926
[finish]: global weight norm at node[9]: 19470.055453707784
Entering next cycle.
Norm: 38759.69566596092 Node ID: 1
getTrainingData
Loading modelfile
Objective Value after gossip/before training: 11233.3
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_1.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_1.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_1.dat
Objective Value after training: 12122.4
WeightVector before pushsum: 
 48:2077.57 57:-4227.28 59:833.095 87:1672.61 95:-4296.39 163:-3660.41 165:-3206.29 285:-10939.3 300:871.64 358:-4593.63 494:1437.09 521:1731.59 523:1315.75 564:868.485 589:963.765 642:912.86 672:-3592.82 677:1014.22 871:4556.4 895:1570.68 1008:-5788.74 1019:1580.59 1077:840.825 1097:1733.06 1114:820.23 1161:755.955 1239:1260.41 1371:1830.06 1518:1224.36 1665:-5827.73 1673:1786.47 1826:2027.16 1827:615.465 1909:925.74 1910:2778.21 1916:-7260.81 1924:802.275 1951:-5989.06 2007:1103.1 2180:3840.58 2192:-1731.46 2205:2173.24 2208:1465.18 2263:903.555 2279:1573.32 2310:878.065 2341:1399.64 2467:-6316.75 2534:1257.27 2572:1335.53 2577:-2635.68 2597:903.82 2656:741.555 2716:1386.53 2763:811.11 2769:2572.67 2816:1150.0 2819:1335.53 2855:2327.13 2907:1624.4 2935:1858.64 2940:2498.89 2982:2392.38 2996:728.335 3088:1854.65 3161:1469.23 3217:-3062.69 3259:376.976 3275:886.31 3376:895.665 3415:840.115 3462:-3018.76 3464:-5327.37 3505:1520.9 3537:1519.46 3654:535.015 3780:657.605 3809:2686.05 3810:1493.41 3812:2256.62 3898:2625.78 4010:2404.55 4154:1662.57 4269:6043.5 4295:1087.34 4324:1158.63 4362:2473.04 4441:1204.12 4453:1872.78 4461:1009.0 4483:900.17 4498:1668.57 4501:1528.88 4628:-4748.61 4702:-7485.81 4724:983.115 4820:952.18 4821:1219.54 4844:1944.69 4954:847.305 5009:1944.69 5201:-2745.75 5258:1225.03 5295:1263.57 5326:1070.8 5370:1092.49 5387:1245.12 5395:1011.6 5430:975.67 5464:1410.12 5615:1658.69 5625:913.505 5657:2546.79 5663:932.555 5785:1370.37 5801:-3785.05 5858:1549.96 5958:629.95 6015:-4345.68 6036:1225.42 6039:1343.85 6233:-10203.1 6235:670.175 6411:-5569.31 6450:-614.056 6459:508.97 6499:1410.12 6502:1622.55 6582:2063.28 6586:903.555 6587:2165.45 6596:714.34 6638:901.78 6659:-4132.06 6660:-3779.85 6714:835.185 6734:1982.44 6744:-4630.83 6766:767.255 6891:842.97 6978:1600.8 6996:1304.52 7058:1671.85 7086:-3222.46 7099:-5606.14 7166:1049.16 7189:1167.54 7250:1389.55 7443:1231.47 7486:1544.06 7517:1503.24 7523:2520.68 7549:620.32 7573:544.84 7576:987.865 7595:1263.57 7611:2060.71 7648:2296.38 7662:3624.44 7758:1715.42 7793:570.195 7970:-22052.5 8027:369.483 8064:-11313.7 8097:626.925 8235:-5489.74 8271:-891.829 8276:1680.79 8279:2469.51 8281:951.915
Node 1 is gossiping with Node 7....
WeightVector after pushsum: 
 48:2077.57 57:-4227.28 59:833.095 87:1672.61 95:-4296.39 163:-3660.41 165:-3206.29 285:-10939.3 300:871.64 358:-4593.63 494:1437.09 521:1731.59 523:1315.75 564:868.485 589:963.765 642:912.86 672:-3592.82 677:1014.22 871:4556.4 895:1570.68 1008:-5788.74 1019:1580.59 1077:840.825 1097:1733.06 1114:820.23 1161:755.955 1239:1260.41 1371:1830.06 1518:1224.36 1665:-5827.73 1673:1786.47 1809:-3455.165 1826:2027.16 1827:615.465 1909:925.74 1910:2778.21 1916:-7260.81 1924:802.275 1951:-5989.06 2007:1103.1 2180:3840.58 2192:-3273.505 2205:2173.24 2208:1465.18 2263:903.555 2279:1573.32 2310:878.065 2341:1399.64 2467:-6316.75 2534:1257.27 2572:1335.53 2577:-2635.68 2597:903.82 2656:741.555 2701:-5174.7 2716:1386.53 2763:811.11 2769:2572.67 2816:1150.0 2819:1335.53 2838:-6131.65 2855:2327.13 2907:1624.4 2935:1858.64 2940:2498.89 2982:2392.38 2996:728.335 3080:-9268.15 3088:1854.65 3161:1469.23 3217:-3062.69 3259:376.976 3275:886.31 3376:895.665 3415:840.115 3462:-3018.76 3464:-5327.37 3505:1520.9 3537:1519.46 3654:535.015 3780:657.605 3809:2686.05 3810:1493.41 3812:2256.62 3898:2625.78 4010:2404.55 4154:1662.57 4269:6043.5 4295:1087.34 4324:1158.63 4362:2473.04 4441:1204.12 4453:1872.78 4461:1009.0 4483:900.17 4498:1668.57 4501:1528.88 4628:-4748.61 4702:-7485.81 4724:983.115 4762:-3595.075 4820:952.18 4821:1219.54 4844:1944.69 4954:847.305 5009:1944.69 5066:-2794.135 5201:-2745.75 5258:1225.03 5295:1263.57 5326:1070.8 5370:1092.49 5387:1245.12 5395:1011.6 5430:975.67 5464:1410.12 5615:1658.69 5625:913.505 5657:2546.79 5663:932.555 5785:1370.37 5801:-3785.05 5858:1549.96 5881:-4928.61 5958:629.95 6015:-4345.68 6036:1225.42 6039:1343.85 6233:-10203.1 6235:670.175 6253:-5520.3 6411:-5569.31 6450:-614.056 6459:508.97 6499:1410.12 6502:1622.55 6582:2063.28 6586:903.555 6587:2165.45 6596:714.34 6638:901.78 6659:-4132.06 6660:-3779.85 6714:835.185 6720:-4429.325 6734:1982.44 6744:-4630.83 6766:767.255 6891:842.97 6978:1600.8 6996:1304.52 7058:1671.85 7086:-3222.46 7099:-5606.14 7166:1049.16 7189:1167.54 7250:1389.55 7443:1231.47 7486:1544.06 7517:1503.24 7523:2520.68 7549:620.32 7573:544.84 7576:987.865 7595:1263.57 7611:2060.71 7648:2296.38 7662:3624.44 7758:1715.42 7793:570.195 7970:-22052.5 8021:-6266.4 8027:369.483 8064:-11313.7 8097:-8109.5875 8235:-5489.74 8271:-1942.2745 8276:1680.79 8279:2469.51 8281:951.915
current node ID: [1]
pred1.dat = predicted labels file
329.786 = avg Loss of solution
(175/330) = number of misclassified examples

Printing out global weights after this round of gossip.
[finish]: global weight norm at node[0]: 27392.244613770814
[finish]: global weight norm at node[1]: 46951.52058385738
[finish]: global weight norm at node[2]: 38759.69880886073
[finish]: global weight norm at node[3]: 38759.66890314651
[finish]: global weight norm at node[4]: 38759.7030136455
[finish]: global weight norm at node[5]: 38759.66325820697
[finish]: global weight norm at node[6]: 38759.67044943623
[finish]: global weight norm at node[7]: 19412.584790344936
[finish]: global weight norm at node[8]: 38759.722676992926
[finish]: global weight norm at node[9]: 19470.055453707784
Entering next cycle.
Norm: 38759.69880886073 Node ID: 2
getTrainingData
Loading modelfile
Objective Value after gossip/before training: 9700.82
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_2.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_2.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_2.dat
Objective Value after training: 2428.15
WeightVector before pushsum: 
 567:-7924.8 1809:-5881.1 2701:-8807.95 4762:-3711.2 5881:-4954.72 6253:-5549.55 6720:-7539.25 8021:-8639.95
Node 2 is gossiping with Node 3....
WeightVector after pushsum: 
 86:-1003.15 138:-1123.505 254:-998.01 300:-946.49 526:-1727.09 557:-1088.715 564:-943.06 567:-7924.8 958:-1224.355 969:-3444.93 971:-1454.695 1008:-706.09 1114:-890.66 1237:-1649.94 1404:-829.58 1463:-2412.79 1480:-1029.11 1529:-1846.13 1643:-755.59 1725:-764.515 1809:-5881.1 1926:-2208.91 2112:-1649.94 2192:-464.3705 2370:-1667.485 2616:-2197.65 2622:-1581.435 2656:-805.235 2701:-8807.95 2753:-865.15 3259:-409.347 3438:-1199.785 3505:-2046.995 3549:-3062.385 3609:-1514.3 3633:-1864.09 3690:-616.79 4023:-5121.35 4024:-4517.63 4046:-1503.525 4142:-2255.97 4146:-986.01 4148:-1057.47 4155:-1149.105 4227:-1939.88 4251:-2725.99 4288:-1400.99 4338:-948.22 4339:-1307.04 4435:-2159.19 4441:-772.24 4501:-1131.39 4762:-2276.107 4797:-2324.475 4800:-1330.22 4851:-1548.515 4900:-4656.25 5147:-693.73 5191:-856.67 5219:-1108.53 5256:-1962.635 5335:-6433.6 5336:-6054.65 5430:-359.635 5818:-931.35 5881:-4954.72 5888:-1473.305 6131:-1738.255 6179:-1393.5 6224:-1129.71 6253:-5549.55 6450:-319.29 6514:-1514.3 6574:-986.01 6586:-981.145 6685:-2255.97 6707:-1809.665 6714:-906.9 6720:-7539.25 6817:-1186.31 6891:-2184.305 6986:-1898.89 7030:-716.51 7246:-1498.28 7256:-2334.935 7319:-790.88 7362:-6168.55 7415:-1238.62 7443:-637.19 7499:-1336.445 7524:-1135.11 7539:-1312.67 7573:-1001.715 7619:-1304.26 7793:-619.155 7893:-1617.595 7946:-1048.925 8021:-8639.95 8027:-401.2115 8233:-1761.88 8235:-1180.71 8277:-900.155
current node ID: [2]
pred2.dat = predicted labels file
0.342424 = avg Loss of solution
(113/330) = number of misclassified examples

Printing out global weights after this round of gossip.
[finish]: global weight norm at node[0]: 27392.244613770814
[finish]: global weight norm at node[1]: 46951.52058385738
[finish]: global weight norm at node[2]: 27246.786559284115
[finish]: global weight norm at node[3]: 19508.506357709335
[finish]: global weight norm at node[4]: 38759.7030136455
[finish]: global weight norm at node[5]: 38759.66325820697
[finish]: global weight norm at node[6]: 38759.67044943623
[finish]: global weight norm at node[7]: 19412.584790344936
[finish]: global weight norm at node[8]: 38759.722676992926
[finish]: global weight norm at node[9]: 19470.055453707784
Entering next cycle.
Norm: 19508.506357709335 Node ID: 3
getTrainingData
Loading modelfile
Objective Value after gossip/before training: 9786.3
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_3.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_3.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_3.dat
Objective Value after training: 12543.6
WeightVector before pushsum: 
 86:-1003.15 138:-1123.51 254:-998.01 300:-946.49 526:-1727.09 557:-1088.71 564:-943.06 672:3604.06 871:6020.08 958:-1224.36 960:5283.73 969:-3444.93 971:-1454.69 1008:-706.09 1114:-890.66 1237:-1649.94 1297:6570.12 1404:-829.58 1463:-2412.79 1480:-1029.11 1529:-1846.13 1643:-755.59 1646:10512.4 1725:-764.515 1826:7284.55 1827:5277.66 1926:-2208.91 2051:8856.57 2112:-1649.94 2192:-464.37 2370:-1667.48 2541:10841.5 2577:7867.46 2616:-2197.65 2622:-1581.43 2656:-805.235 2753:-865.15 2990:10365.8 3259:-409.347 3438:-1199.79 3505:-2046.99 3549:-3062.39 3609:-1514.3 3633:-1864.09 3690:-616.79 3780:5639.02 3791:3244.47 3898:4763.47 4023:-5121.35 4024:-4517.63 4046:-1503.53 4142:-2255.97 4146:-986.01 4148:-1057.47 4155:-1149.11 4159:6465.3 4227:-1939.88 4251:-2725.99 4288:5133.33 4338:-948.22 4339:-1307.04 4435:-2159.19 4441:-772.24 4498:4991.05 4501:-1131.39 4621:8005.04 4762:-420.507 4797:-2324.47 4800:-1330.22 4802:5489.77 4820:2848.18 4851:-1548.52 4900:-4656.25 5147:-693.73 5191:-856.67 5214:11215.1 5219:-1108.53 5256:-1962.63 5335:-6433.6 5336:-6054.65 5430:-359.635 5591:3280.45 5675:6588.36 5728:5595.88 5818:-931.35 5888:-1473.31 5893:3570.21 5958:5401.87 6128:5472.82 6131:-1738.26 6179:-1393.5 6224:-1129.71 6450:737.336 6514:-1514.3 6574:-986.01 6586:-981.145 6685:-2255.97 6707:-1809.66 6714:-906.9 6768:12002.1 6817:-1186.31 6891:-2184.3 6986:-1898.89 7027:4438.84 7030:-716.51 7246:-1498.28 7256:-2334.93 7319:-790.88 7362:-6168.55 7415:-1238.62 7443:-637.19 7457:2302.62 7463:4640.6 7499:-1336.44 7524:-1135.11 7539:-1312.67 7573:3670.35 7611:4973.11 7619:-1304.26 7793:-619.155 7893:-1617.6 7946:-1048.92 8027:-401.212 8233:-1761.88 8235:-1180.71 8271:1346.02 8276:5027.61 8277:-900.155
Node 3 is gossiping with Node 7....
WeightVector after pushsum: 
 86:-1003.15 138:-1123.51 254:-998.01 300:-946.49 526:-1727.09 557:-1088.71 564:-943.06 672:3604.06 871:6020.08 958:-1224.36 960:5283.73 969:-3444.93 971:-1454.69 1008:-706.09 1114:-890.66 1237:-1649.94 1297:6570.12 1404:-829.58 1463:-2412.79 1480:-1029.11 1529:-1846.13 1643:-755.59 1646:10512.4 1725:-764.515 1809:-1727.5825 1826:7284.55 1827:5277.66 1926:-2208.91 2051:8856.57 2112:-1649.94 2192:-1868.9375 2370:-1667.48 2541:10841.5 2577:7867.46 2616:-2197.65 2622:-1581.43 2656:-805.235 2701:-2587.35 2753:-865.15 2838:-3065.825 2990:10365.8 3080:-4634.075 3259:-409.347 3438:-1199.79 3505:-2046.99 3549:-3062.39 3609:-1514.3 3633:-1864.09 3690:-616.79 3780:5639.02 3791:3244.47 3898:4763.47 4023:-5121.35 4024:-4517.63 4046:-1503.53 4142:-2255.97 4146:-986.01 4148:-1057.47 4155:-1149.11 4159:6465.3 4227:-1939.88 4251:-2725.99 4288:5133.33 4338:-948.22 4339:-1307.04 4435:-2159.19 4441:-772.24 4498:4991.05 4501:-1131.39 4621:8005.04 4762:-2007.791 4797:-2324.47 4800:-1330.22 4802:5489.77 4820:2848.18 4851:-1548.52 4900:-4656.25 5066:-1397.0675 5147:-693.73 5191:-856.67 5214:11215.1 5219:-1108.53 5256:-1962.63 5335:-6433.6 5336:-6054.65 5430:-359.635 5591:3280.45 5675:6588.36 5728:5595.88 5818:-931.35 5881:-2464.305 5888:-1473.31 5893:3570.21 5958:5401.87 6128:5472.82 6131:-1738.26 6179:-1393.5 6224:-1129.71 6253:-2760.15 6450:737.336 6514:-1514.3 6574:-986.01 6586:-981.145 6685:-2255.97 6707:-1809.66 6714:-906.9 6720:-2214.6625 6768:12002.1 6817:-1186.31 6891:-2184.3 6986:-1898.89 7027:4438.84 7030:-716.51 7246:-1498.28 7256:-2334.93 7319:-790.88 7362:-6168.55 7415:-1238.62 7443:-637.19 7457:2302.62 7463:4640.6 7499:-1336.44 7524:-1135.11 7539:-1312.67 7573:3670.35 7611:4973.11 7619:-1304.26 7793:-619.155 7893:-1617.6 7946:-1048.92 8021:-3133.2 8027:-401.212 8097:-4054.79375 8233:-1761.88 8235:-1180.71 8271:-298.12725 8276:5027.61 8277:-900.155
current node ID: [3]
pred3.dat = predicted labels file
670.581 = avg Loss of solution
(227/330) = number of misclassified examples

Printing out global weights after this round of gossip.
[finish]: global weight norm at node[0]: 27392.244613770814
[finish]: global weight norm at node[1]: 46951.52058385738
[finish]: global weight norm at node[2]: 27246.786559284115
[finish]: global weight norm at node[3]: 44071.73638964502
[finish]: global weight norm at node[4]: 38759.7030136455
[finish]: global weight norm at node[5]: 38759.66325820697
[finish]: global weight norm at node[6]: 38759.67044943623
[finish]: global weight norm at node[7]: 9745.354617860892
[finish]: global weight norm at node[8]: 38759.722676992926
[finish]: global weight norm at node[9]: 19470.055453707784
Entering next cycle.
Norm: 38759.7030136455 Node ID: 4
getTrainingData
Loading modelfile
Objective Value after gossip/before training: 9715.38
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_4.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_4.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_4.dat
Objective Value after training: 2435.31
WeightVector before pushsum: 
 59:-1806.59 146:-2797.82 147:-6194.9 300:-1890.17 876:-2674.8 1516:-818.68 1533:-1704.4 1616:-3406.76 1743:-8960.5 2082:-2914.16 2192:-547.715 2279:-1625.73 2314:-1639.3 2546:-1944.14 2576:-2650.51 2597:-1959.96 3259:-817.48 3618:-2380.49 3661:-1239.45 3791:-2352.11 3812:-2050.68 5201:-1996.8 5310:-2992.11 5430:-718.205 5776:-2035.21 5843:-3518.55 6235:-1453.29 6329:-5067.0 6387:-3427.55 6450:-637.635 6459:-2316.28 6596:-1549.06 6748:-2471.18 6817:-2369.1 6839:-3278.19 6893:-5051.25 7163:-1780.12 7575:-4144.9 7765:-2466.75 7793:-1236.47 7898:-2896.13 7913:-1797.64 8229:-2878.61
Node 4 is gossiping with Node 5....
WeightVector after pushsum: 
 59:-1806.59 146:-2797.82 147:-6194.9 300:-1890.17 567:-6432.9 876:-2674.8 1516:-818.68 1533:-1704.4 1616:-3406.76 1694:-1896.1 1743:-8960.5 1809:-3494.79 2054:-3660.65 2082:-2914.16 2192:-1434.3325 2279:-1625.73 2314:-1639.3 2447:-4533.32 2546:-1944.14 2576:-2650.51 2597:-1959.96 3259:-817.48 3618:-2380.49 3661:-1239.45 3791:-2352.11 3812:-2050.68 3892:-3903.085 4748:-8782.0 4762:-3470.555 4770:-9835.35 5201:-1996.8 5310:-2992.11 5430:-718.205 5776:-2035.21 5843:-3518.55 5881:-2375.44 6235:-1453.29 6253:-4504.82 6329:-5067.0 6387:-3427.55 6450:-637.635 6459:-2316.28 6596:-1549.06 6720:-5094.25 6748:-2471.18 6817:-2369.1 6839:-3278.19 6893:-5051.25 7163:-1780.12 7575:-4144.9 7765:-2466.75 7793:-1236.47 7898:-2896.13 7913:-1797.64 8021:-5345.45 8229:-2878.61 8271:-1221.095
current node ID: [4]
pred4.dat = predicted labels file
0.148485 = avg Loss of solution
(49/330) = number of misclassified examples

Printing out global weights after this round of gossip.
[finish]: global weight norm at node[0]: 27392.244613770814
[finish]: global weight norm at node[1]: 46951.52058385738
[finish]: global weight norm at node[2]: 27246.786559284115
[finish]: global weight norm at node[3]: 44071.73638964502
[finish]: global weight norm at node[4]: 27414.72314804549
[finish]: global weight norm at node[5]: 19398.156651273108
[finish]: global weight norm at node[6]: 38759.67044943623
[finish]: global weight norm at node[7]: 9745.354617860892
[finish]: global weight norm at node[8]: 38759.722676992926
[finish]: global weight norm at node[9]: 19470.055453707784
Entering next cycle.
Norm: 19398.156651273108 Node ID: 5
getTrainingData
Loading modelfile
Objective Value after gossip/before training: 9703.6
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_5.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_5.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_5.dat
Objective Value after training: 12237
WeightVector before pushsum: 
 567:-6432.9 799:-15974.3 1694:-1896.1 1809:-3494.79 2054:-3660.65 2125:-18539.2 2192:-1160.47 2447:-4533.32 2656:-12277.2 3892:-3903.09 4748:-8782.0 4762:-3470.55 4770:-9835.35 5430:-5483.26 5881:-2375.44 5958:-10429.4 6253:-4504.82 6720:-5094.25 7405:-14605.0 7542:-20014.0 8021:-5345.45 8271:-1221.1
Node 5 is gossiping with Node 3....
WeightVector after pushsum: 
 86:-501.575 138:-561.755 254:-499.005 300:-473.245 526:-863.545 557:-544.355 564:-471.53 567:-6432.9 672:1802.03 799:-15974.3 871:3010.04 958:-612.18 960:2641.865 969:-1722.465 971:-727.345 1008:-353.045 1114:-445.33 1237:-824.97 1297:3285.06 1404:-414.79 1463:-1206.395 1480:-514.555 1529:-923.065 1643:-377.795 1646:5256.2 1694:-1896.1 1725:-382.2575 1809:-2611.1862499999997 1826:3642.275 1827:2638.83 1926:-1104.455 2051:4428.285 2054:-3660.65 2112:-824.97 2125:-18539.2 2192:-1514.7037500000001 2370:-833.74 2447:-4533.32 2541:5420.75 2577:3933.73 2616:-1098.825 2622:-790.715 2656:-6541.217500000001 2701:-1293.675 2753:-432.575 2838:-1532.9125 2990:5182.9 3080:-2317.0375 3259:-204.6735 3438:-599.895 3505:-1023.495 3549:-1531.195 3609:-757.15 3633:-932.045 3690:-308.395 3780:2819.51 3791:1622.235 3892:-3903.09 3898:2381.735 4023:-2560.675 4024:-2258.815 4046:-751.765 4142:-1127.985 4146:-493.005 4148:-528.735 4155:-574.555 4159:3232.65 4227:-969.94 4251:-1362.995 4288:2566.665 4338:-474.11 4339:-653.52 4435:-1079.595 4441:-386.12 4498:2495.525 4501:-565.695 4621:4002.52 4748:-8782.0 4762:-2739.1705 4770:-9835.35 4797:-1162.235 4800:-665.11 4802:2744.885 4820:1424.09 4851:-774.26 4900:-2328.125 5066:-698.53375 5147:-346.865 5191:-428.335 5214:5607.55 5219:-554.265 5256:-981.315 5335:-3216.8 5336:-3027.325 5430:-2921.4475 5591:1640.225 5675:3294.18 5728:2797.94 5818:-465.675 5881:-2419.8725 5888:-736.655 5893:1785.105 5958:-2513.765 6128:2736.41 6131:-869.13 6179:-696.75 6224:-564.855 6253:-3632.4849999999997 6450:368.668 6514:-757.15 6574:-493.005 6586:-490.5725 6685:-1127.985 6707:-904.83 6714:-453.45 6720:-3654.45625 6768:6001.05 6817:-593.155 6891:-1092.15 6986:-949.445 7027:2219.42 7030:-358.255 7246:-749.14 7256:-1167.465 7319:-395.44 7362:-3084.275 7405:-14605.0 7415:-619.31 7443:-318.595 7457:1151.31 7463:2320.3 7499:-668.22 7524:-567.555 7539:-656.335 7542:-20014.0 7573:1835.175 7611:2486.555 7619:-652.13 7793:-309.5775 7893:-808.8 7946:-524.46 8021:-4239.325 8027:-200.606 8097:-2027.396875 8233:-880.94 8235:-590.355 8271:-759.613625 8276:2513.805 8277:-450.0775
current node ID: [5]
pred5.dat = predicted labels file
0.10303 = avg Loss of solution
(34/330) = number of misclassified examples

Printing out global weights after this round of gossip.
[finish]: global weight norm at node[0]: 27392.244613770814
[finish]: global weight norm at node[1]: 46951.52058385738
[finish]: global weight norm at node[2]: 27246.786559284115
[finish]: global weight norm at node[3]: 24362.863672811334
[finish]: global weight norm at node[4]: 27414.72314804549
[finish]: global weight norm at node[5]: 45544.659795693835
[finish]: global weight norm at node[6]: 38759.67044943623
[finish]: global weight norm at node[7]: 9745.354617860892
[finish]: global weight norm at node[8]: 38759.722676992926
[finish]: global weight norm at node[9]: 19470.055453707784
Entering next cycle.
Norm: 38759.67044943623 Node ID: 6
getTrainingData
Loading modelfile
Objective Value after gossip/before training: 9715.22
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_6.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_6.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_6.dat
Objective Value after training: 2435.23
WeightVector before pushsum: 
 567:-5258.15 1809:-2974.11 2092:-8226.25 2192:-2222.73 2496:-2939.37 2581:-2363.94 2627:-2688.64 2996:-1940.77 3654:-2413.8 3656:-2405.3 3690:-1513.56 3810:-1896.22 4353:-1424.99 4762:-1876.78 4861:-5057.7 5066:-1322.39 5201:-4269.08 5742:-8415.65 5881:-3287.49 6253:-3682.16 6582:-1969.35 6720:-3812.64 7820:-5920.8 8021:-3797.94 8125:-3009.74 8271:-708.185
Node 6 is gossiping with Node 1....
WeightVector after pushsum: 
 48:1038.785 57:-2113.64 59:416.5475 87:836.305 95:-2148.195 163:-1830.205 165:-1603.145 285:-5469.65 300:435.82 358:-2296.815 494:718.545 521:865.795 523:657.875 564:434.2425 567:-5258.15 589:481.8825 642:456.43 672:-1796.41 677:507.11 871:2278.2 895:785.34 1008:-2894.37 1019:790.295 1077:420.4125 1097:866.53 1114:410.115 1161:377.9775 1239:630.205 1371:915.03 1518:612.18 1665:-2913.865 1673:893.235 1809:-3214.6375 1826:1013.58 1827:307.7325 1909:462.87 1910:1389.105 1916:-3630.405 1924:401.1375 1951:-2994.53 2007:551.55 2092:-8226.25 2180:1920.29 2192:-2748.1175000000003 2205:1086.62 2208:732.59 2263:451.7775 2279:786.66 2310:439.0325 2341:699.82 2467:-3158.375 2496:-2939.37 2534:628.635 2572:667.765 2577:-1317.84 2581:-2363.94 2597:451.91 2627:-2688.64 2656:370.7775 2701:-2587.35 2716:693.265 2763:405.555 2769:1286.335 2816:575.0 2819:667.765 2838:-3065.825 2855:1163.565 2907:812.2 2935:929.32 2940:1249.445 2982:1196.19 2996:-606.2175 3080:-4634.075 3088:927.325 3161:734.615 3217:-1531.345 3259:188.488 3275:443.155 3376:447.8325 3415:420.0575 3462:-1509.38 3464:-2663.685 3505:760.45 3537:759.73 3654:-939.3925000000002 3656:-2405.3 3690:-1513.56 3780:328.8025 3809:1343.025 3810:-201.40499999999997 3812:1128.31 3898:1312.89 4010:1202.275 4154:831.285 4269:3021.75 4295:543.67 4324:579.315 4353:-1424.99 4362:1236.52 4441:602.06 4453:936.39 4461:504.5 4483:450.085 4498:834.285 4501:764.44 4628:-2374.305 4702:-3742.905 4724:491.5575 4762:-2735.9275 4820:476.09 4821:609.77 4844:972.345 4861:-5057.7 4954:423.6525 5009:972.345 5066:-2058.2625000000003 5201:-3507.415 5258:612.515 5295:631.785 5326:535.4 5370:546.245 5387:622.56 5395:505.8 5430:487.835 5464:705.06 5615:829.345 5625:456.7525 5657:1273.395 5663:466.2775 5742:-8415.65 5785:685.185 5801:-1892.525 5858:774.98 5881:-4108.049999999999 5958:314.975 6015:-2172.84 6036:612.71 6039:671.925 6233:-5101.55 6235:335.0875 6253:-4601.23 6411:-2784.655 6450:-307.028 6459:254.485 6499:705.06 6502:811.275 6582:46.965000000000146 6586:451.7775 6587:1082.725 6596:357.17 6638:450.89 6659:-2066.03 6660:-1889.925 6714:417.5925 6720:-4120.9825 6734:991.22 6744:-2315.415 6766:383.6275 6891:421.485 6978:800.4 6996:652.26 7058:835.925 7086:-1611.23 7099:-2803.07 7166:524.58 7189:583.77 7250:694.775 7443:615.735 7486:772.03 7517:751.62 7523:1260.34 7549:310.16 7573:272.42 7576:493.9325 7595:631.785 7611:1030.355 7648:1148.19 7662:1812.22 7758:857.71 7793:285.0975 7820:-5920.8 7970:-11026.25 8021:-5032.17 8027:184.7415 8064:-5656.85 8097:-4054.79375 8125:-3009.74 8235:-2744.87 8271:-1325.22975 8276:840.395 8279:1234.755 8281:475.9575
current node ID: [6]
pred6.dat = predicted labels file
0.169697 = avg Loss of solution
(56/330) = number of misclassified examples

Printing out global weights after this round of gossip.
[finish]: global weight norm at node[0]: 27392.244613770814
[finish]: global weight norm at node[1]: 25149.739472259815
[finish]: global weight norm at node[2]: 27246.786559284115
[finish]: global weight norm at node[3]: 24362.863672811334
[finish]: global weight norm at node[4]: 27414.72314804549
[finish]: global weight norm at node[5]: 45544.659795693835
[finish]: global weight norm at node[6]: 29998.507455562565
[finish]: global weight norm at node[7]: 9745.354617860892
[finish]: global weight norm at node[8]: 38759.722676992926
[finish]: global weight norm at node[9]: 19470.055453707784
Entering next cycle.
Norm: 9745.354617860892 Node ID: 7
getTrainingData
Loading modelfile
Objective Value after gossip/before training: 9725.12
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_7.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_7.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_7.dat
Objective Value after training: 2440.19
WeightVector before pushsum: 
 1809:-3455.16 2192:-2407.78 2701:-5174.7 2838:-6131.65 3080:-9268.15 4762:-3595.07 5066:-2794.14 5881:-4928.61 6253:-5520.3 6720:-4429.32 8021:-6266.4 8097:-8423.05 8271:-1496.36
Node 7 is gossiping with Node 0....
WeightVector after pushsum: 
 75:-1078.4875 285:-1983.2425 407:-1367.59 494:-1197.3325 642:-2431.695 1008:-917.2925 1297:-3840.5 1477:-1566.4 1533:-1108.7525 1694:-1102.2325 1809:-3274.305 2175:-1932.42 2192:-1560.1925 2394:-3134.5 2701:-5174.7 2828:-3296.2 2838:-6131.65 3080:-9268.15 4431:-1480.455 4472:-1364.24 4624:-2045.7025 4762:-2120.1800000000003 4918:-2456.96 5054:-1524.38 5066:-2794.14 5329:-1698.01 5374:-4060.75 5752:-1824.955 5880:-2124.64 5881:-4928.61 5894:-2415.375 6036:-1471.725 6253:-5520.3 6450:-173.82375 6632:-1586.045 6720:-4429.32 7030:-930.83 7170:-2696.35 7706:-5600.35 7791:-5395.4 7793:-1361.89 8021:-4085.43 8097:-8423.05 8271:-1496.36
current node ID: [7]
pred7.dat = predicted labels file
0.254545 = avg Loss of solution
(84/330) = number of misclassified examples

Printing out global weights after this round of gossip.
[finish]: global weight norm at node[0]: 14778.186294890489
[finish]: global weight norm at node[1]: 25149.739472259815
[finish]: global weight norm at node[2]: 27246.786559284115
[finish]: global weight norm at node[3]: 24362.863672811334
[finish]: global weight norm at node[4]: 27414.72314804549
[finish]: global weight norm at node[5]: 45544.659795693835
[finish]: global weight norm at node[6]: 29998.507455562565
[finish]: global weight norm at node[7]: 22892.04913452898
[finish]: global weight norm at node[8]: 38759.722676992926
[finish]: global weight norm at node[9]: 19470.055453707784
Entering next cycle.
Norm: 38759.722676992926 Node ID: 8
getTrainingData
Loading modelfile
Objective Value after gossip/before training: 9781.26
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_8.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_8.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_8.dat
Objective Value after training: 2468.3
WeightVector before pushsum: 
 149:-3073.86 165:-2474.81 373:-3366.63 407:-1248.86 1438:-5617.75 1462:-4024.88 1505:-1749.69 1626:-2225.85 1629:-3497.2 1643:-2711.64 1712:-2494.84 1965:-5801.65 2135:-2233.59 2534:-1709.09 2570:-3396.9 2616:-1456.93 2990:-1974.08 3213:-3046.17 3217:-1396.2 3296:-3283.45 3436:-3788.74 3456:-4399.27 3791:-1474.45 3846:-1767.18 4010:-2637.14 4602:-2725.02 4612:-2083.74 5225:-2564.26 5607:-3428.64 5768:-1684.1 5801:-1725.5 5806:-2586.16 5915:-6551.05 5978:-2089.94 6236:-3093.01 6450:-595.175 6624:-2203.2 6937:-2697.71 7298:-1744.78 7323:-3282.22 7443:-1350.59 7457:-1771.76 7499:-1673.05 8027:-850.405 8224:-2047.68
Node 8 is gossiping with Node 5....
WeightVector after pushsum: 
 86:-250.7875 138:-280.8775 149:-3073.86 165:-2474.81 254:-249.5025 300:-236.6225 373:-3366.63 407:-1248.86 526:-431.7725 557:-272.1775 564:-235.765 567:-3216.45 672:901.015 799:-7987.15 871:1505.02 958:-306.09 960:1320.9325 969:-861.2325 971:-363.6725 1008:-176.5225 1114:-222.665 1237:-412.485 1297:1642.53 1404:-207.395 1438:-5617.75 1462:-4024.88 1463:-603.1975 1480:-257.2775 1505:-1749.69 1529:-461.5325 1626:-2225.85 1629:-3497.2 1643:-1544.7175 1646:2628.1 1694:-948.05 1712:-2494.84 1725:-191.12875 1809:-1305.5931249999999 1826:1821.1375 1827:1319.415 1926:-552.2275 1965:-5801.65 2051:2214.1425 2054:-1830.325 2112:-412.485 2125:-9269.6 2135:-2233.59 2192:-757.3518750000001 2370:-416.87 2447:-2266.66 2534:-1709.09 2541:2710.375 2570:-3396.9 2577:1966.865 2616:-1277.8775 2622:-395.3575 2656:-3270.6087500000003 2701:-646.8375 2753:-216.2875 2838:-766.45625 2990:1604.4099999999999 3080:-1158.51875 3213:-3046.17 3217:-1396.2 3259:-102.33675 3296:-3283.45 3436:-3788.74 3438:-299.9475 3456:-4399.27 3505:-511.7475 3549:-765.5975 3609:-378.575 3633:-466.0225 3690:-154.1975 3780:1409.755 3791:73.89249999999993 3846:-1767.18 3892:-1951.545 3898:1190.8675 4010:-2637.14 4023:-1280.3375 4024:-1129.4075 4046:-375.8825 4142:-563.9925 4146:-246.5025 4148:-264.3675 4155:-287.2775 4159:1616.325 4227:-484.97 4251:-681.4975 4288:1283.3325 4338:-237.055 4339:-326.76 4435:-539.7975 4441:-193.06 4498:1247.7625 4501:-282.8475 4602:-2725.02 4612:-2083.74 4621:2001.26 4748:-4391.0 4762:-1369.58525 4770:-4917.675 4797:-581.1175 4800:-332.555 4802:1372.4425 4820:712.045 4851:-387.13 4900:-1164.0625 5066:-349.266875 5147:-173.4325 5191:-214.1675 5214:2803.775 5219:-277.1325 5225:-2564.26 5256:-490.6575 5335:-1608.4 5336:-1513.6625 5430:-1460.72375 5591:820.1125 5607:-3428.64 5675:1647.09 5728:1398.97 5768:-1684.1 5801:-1725.5 5806:-2586.16 5818:-232.8375 5881:-1209.93625 5888:-368.3275 5893:892.5525 5915:-6551.05 5958:-1256.8825 5978:-2089.94 6128:1368.205 6131:-434.565 6179:-348.375 6224:-282.4275 6236:-3093.01 6253:-1816.2424999999998 6450:-113.25349999999997 6514:-378.575 6574:-246.5025 6586:-245.28625 6624:-2203.2 6685:-563.9925 6707:-452.415 6714:-226.725 6720:-1827.228125 6768:3000.525 6817:-296.5775 6891:-546.075 6937:-2697.71 6986:-474.7225 7027:1109.71 7030:-179.1275 7246:-374.57 7256:-583.7325 7298:-1744.78 7319:-197.72 7323:-3282.22 7362:-1542.1375 7405:-7302.5 7415:-309.655 7443:-834.5925 7457:-310.225 7463:1160.15 7499:-1170.635 7524:-283.7775 7539:-328.1675 7542:-10007.0 7573:917.5875 7611:1243.2775 7619:-326.065 7793:-154.78875 7893:-404.4 7946:-262.23 8021:-2119.6625 8027:-525.5055 8097:-1013.6984375 8224:-2047.68 8233:-440.47 8235:-295.1775 8271:-379.8068125 8276:1256.9025 8277:-225.03875
current node ID: [8]
pred8.dat = predicted labels file
0.527273 = avg Loss of solution
(174/330) = number of misclassified examples

Printing out global weights after this round of gossip.
[finish]: global weight norm at node[0]: 14778.186294890489
[finish]: global weight norm at node[1]: 25149.739472259815
[finish]: global weight norm at node[2]: 27246.786559284115
[finish]: global weight norm at node[3]: 24362.863672811334
[finish]: global weight norm at node[4]: 27414.72314804549
[finish]: global weight norm at node[5]: 22790.489065059028
[finish]: global weight norm at node[6]: 29998.507455562565
[finish]: global weight norm at node[7]: 22892.04913452898
[finish]: global weight norm at node[8]: 29505.91680478298
[finish]: global weight norm at node[9]: 19470.055453707784
Entering next cycle.
Norm: 19470.055453707784 Node ID: 9
getTrainingData
Loading modelfile
Objective Value after gossip/before training: 9805.56
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_9.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_9.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_9.dat
Objective Value after training: 2480.37
WeightVector before pushsum: 
 75:-2156.97 285:-3966.49 494:-2394.66 642:-4863.39 1008:-1834.59 1297:-7681.0 1477:-3132.8 1533:-2217.51 1694:-1164.33 2192:-712.605 2394:-6269.0 2828:-6592.4 4472:-2728.48 4624:-4091.41 4762:-645.29 4918:-4913.92 5054:-3048.76 5374:-8121.5 6450:-347.647 7030:-1861.66 7170:-5392.7 7793:-2723.78
Node 9 is gossiping with Node 5....
WeightVector after pushsum: 
 75:-2156.97 86:-125.39375 138:-140.43875 254:-124.75125 285:-3966.49 300:-118.31125 494:-2394.66 526:-215.88625 557:-136.08875 564:-117.8825 567:-1608.225 642:-4863.39 672:450.5075 799:-3993.575 871:752.51 958:-153.045 960:660.46625 969:-430.61625 971:-181.83625 1008:-1005.55625 1114:-111.3325 1237:-206.2425 1297:-3019.235 1404:-103.6975 1463:-301.59875 1477:-3132.8 1480:-128.63875 1529:-230.76625 1533:-2217.51 1643:-772.35875 1646:1314.05 1694:-1056.19 1725:-95.564375 1809:-652.7965624999999 1826:910.56875 1827:659.7075 1926:-276.11375 2051:1107.07125 2054:-915.1625 2112:-206.2425 2125:-4634.8 2192:-734.9784375 2370:-208.435 2394:-6269.0 2447:-1133.33 2541:1355.1875 2577:983.4325 2616:-638.93875 2622:-197.67875 2656:-1635.3043750000002 2701:-323.41875 2753:-108.14375 2828:-6592.4 2838:-383.228125 2990:802.2049999999999 3080:-579.259375 3259:-51.168375 3438:-149.97375 3505:-255.87375 3549:-382.79875 3609:-189.2875 3633:-233.01125 3690:-77.09875 3780:704.8775 3791:36.946249999999964 3892:-975.7725 3898:595.43375 4023:-640.16875 4024:-564.70375 4046:-187.94125 4142:-281.99625 4146:-123.25125 4148:-132.18375 4155:-143.63875 4159:808.1625 4227:-242.485 4251:-340.74875 4288:641.66625 4338:-118.5275 4339:-163.38 4435:-269.89875 4441:-96.53 4472:-2728.48 4498:623.88125 4501:-141.42375 4621:1000.63 4624:-4091.41 4748:-2195.5 4762:-1007.437625 4770:-2458.8375 4797:-290.55875 4800:-166.2775 4802:686.22125 4820:356.0225 4851:-193.565 4900:-582.03125 4918:-4913.92 5054:-3048.76 5066:-174.6334375 5147:-86.71625 5191:-107.08375 5214:1401.8875 5219:-138.56625 5256:-245.32875 5335:-804.2 5336:-756.83125 5374:-8121.5 5430:-730.361875 5591:410.05625 5675:823.545 5728:699.485 5818:-116.41875 5881:-604.968125 5888:-184.16375 5893:446.27625 5958:-628.44125 6128:684.1025 6131:-217.2825 6179:-174.1875 6224:-141.21375 6253:-908.1212499999999 6450:-230.45024999999998 6514:-189.2875 6574:-123.25125 6586:-122.643125 6685:-281.99625 6707:-226.2075 6714:-113.3625 6720:-913.6140625 6768:1500.2625 6817:-148.28875 6891:-273.0375 6986:-237.36125 7027:554.855 7030:-1020.3937500000001 7170:-5392.7 7246:-187.285 7256:-291.86625 7319:-98.86 7362:-771.06875 7405:-3651.25 7415:-154.8275 7443:-417.29625 7457:-155.1125 7463:580.075 7499:-585.3175 7524:-141.88875 7539:-164.08375 7542:-5003.5 7573:458.79375 7611:621.63875 7619:-163.0325 7793:-1439.2843750000002 7893:-202.2 7946:-131.115 8021:-1059.83125 8027:-262.75275 8097:-506.84921875 8233:-220.235 8235:-147.58875 8271:-189.90340625 8276:628.45125 8277:-112.519375
current node ID: [9]
pred9.dat = predicted labels file
0.0759878 = avg Loss of solution
(25/329) = number of misclassified examples

Printing out global weights after this round of gossip.
[finish]: global weight norm at node[0]: 14778.186294890489
[finish]: global weight norm at node[1]: 25149.739472259815
[finish]: global weight norm at node[2]: 27246.786559284115
[finish]: global weight norm at node[3]: 24362.863672811334
[finish]: global weight norm at node[4]: 27414.72314804549
[finish]: global weight norm at node[5]: 12011.599070844519
[finish]: global weight norm at node[6]: 29998.507455562565
[finish]: global weight norm at node[7]: 22892.04913452898
[finish]: global weight norm at node[8]: 29505.91680478298
[finish]: global weight norm at node[9]: 21076.25869289929
Entering next cycle.
Norm: 14778.186294890489 Node ID: 0
getTrainingData
Loading modelfile
Objective Value after gossip/before training: 2431.71
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_0.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_0.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_0.dat
Objective Value after training: 11369
WeightVector before pushsum: 
 35:3077.26 59:2506.75 87:1755.57 95:1512.3 116:2212.76 243:1638.38 317:3107.72 386:2427.16 390:2087.08 407:-1367.59 411:2686.53 412:6049.83 545:1766.33 557:1781.79 576:2791.89 606:7576.04 642:2500.22 799:1714.7 871:6222.99 986:3948.77 1077:1494.26 1114:4294.13 1179:2883.5 1261:1395.74 1360:3295.98 1389:4526.0 1497:1880.63 1516:1601.01 1676:1938.44 1694:-1040.14 1695:1795.43 1712:1926.33 1725:1251.2 1728:2673.13 1809:-1546.72 1826:1509.68 1918:2608.51 1921:2844.83 1950:2808.93 1990:2971.1 2016:4699.19 2054:2397.34 2102:2047.5 2121:2995.61 2175:-1932.42 2181:2611.02 2203:1768.51 2208:1537.86 2291:1490.48 2299:3804.23 2310:1560.45 2339:1993.42 2420:2947.72 2531:3621.81 2532:2239.92 2555:2588.18 2577:3018.8 2594:2157.71 2622:4382.17 2638:3479.7 2656:1317.85 2662:2443.64 2764:3272.51 2775:1421.35 2808:2496.57 2813:3455.98 2855:1293.5 2875:2305.42 2902:7030.77 3032:5851.48 3149:1999.12 3182:4528.2 3222:2729.01 3253:7005.3 3259:1134.3 3285:3077.26 3391:3140.15 3462:1325.03 3487:1828.78 3615:3140.15 3618:1950.85 3659:4990.93 3733:3343.87 3756:1793.13 3758:6258.87 3791:1138.47 3806:2545.39 3810:2141.23 3812:3526.85 3846:2310.28 3938:1944.6 4109:4503.9 4121:4309.72 4125:6457.98 4146:2732.24 4161:3392.7 4321:1566.25 4324:2059.05 4431:-1480.45 4501:3328.61 4637:2157.71 4801:3599.43 4851:1496.8 4918:2008.36 4954:1505.78 4955:2373.42 5145:1180.04 5147:1922.33 5154:1170.64 5178:6916.98 5191:1402.02 5329:-1698.01 5395:1797.74 5430:588.579 5550:2634.95 5591:1151.09 5694:3212.05 5741:1579.16 5752:-1824.95 5786:2505.97 5795:3295.98 5844:1643.46 5864:2599.47 5876:6286.62 5880:-2124.64 5894:-2415.38 5940:1364.49 5988:1819.03 6000:1932.35 6015:1529.65 6018:2686.53 6036:-1471.72 6041:2324.87 6093:4460.77 6099:2262.76 6137:3948.77 6139:4816.72 6141:2315.26 6184:992.839 6194:2134.55 6197:1597.9 6258:3202.87 6316:3343.87 6449:1132.27 6450:744.07 6504:6398.56 6582:1313.41 6632:-467.738 6659:1295.74 6661:1976.62 6707:1749.23 6802:2673.13 6878:3455.98 6923:2366.19 7016:2202.29 7030:1985.46 7063:2714.44 7086:3083.01 7140:1983.27 7245:2588.18 7293:3048.55 7320:1929.33 7415:1197.26 7457:807.977 7573:968.259 7577:2577.14 7611:1745.04 7693:6916.98 7706:-5600.35 7760:2904.01 7791:-5395.4 7793:1013.31 7924:2286.69 7935:2808.93 7946:1716.67 8021:-952.23 8032:1708.85
Node 0 is gossiping with Node 7....
WeightVector after pushsum: 
 35:3077.26 59:2506.75 75:-539.24375 87:1755.57 95:1512.3 116:2212.76 243:1638.38 285:-991.62125 317:3107.72 386:2427.16 390:2087.08 407:-1367.59 411:2686.53 412:6049.83 494:-598.66625 545:1766.33 557:1781.79 576:2791.89 606:7576.04 642:34.26249999999982 799:1714.7 871:6222.99 986:3948.77 1008:-458.64625 1077:1494.26 1114:4294.13 1179:2883.5 1261:1395.74 1297:-1920.25 1360:3295.98 1389:4526.0 1477:-783.2 1497:1880.63 1516:1601.01 1533:-554.37625 1676:1938.44 1694:-1071.1862500000002 1695:1795.43 1712:1926.33 1725:1251.2 1728:2673.13 1809:-2410.5125 1826:1509.68 1918:2608.51 1921:2844.83 1950:2808.93 1990:2971.1 2016:4699.19 2054:2397.34 2102:2047.5 2121:2995.61 2175:-1932.42 2181:2611.02 2192:-780.09625 2203:1768.51 2208:1537.86 2291:1490.48 2299:3804.23 2310:1560.45 2339:1993.42 2394:-1567.25 2420:2947.72 2531:3621.81 2532:2239.92 2555:2588.18 2577:3018.8 2594:2157.71 2622:4382.17 2638:3479.7 2656:1317.85 2662:2443.64 2701:-2587.35 2764:3272.51 2775:1421.35 2808:2496.57 2813:3455.98 2828:-1648.1 2838:-3065.825 2855:1293.5 2875:2305.42 2902:7030.77 3032:5851.48 3080:-4634.075 3149:1999.12 3182:4528.2 3222:2729.01 3253:7005.3 3259:1134.3 3285:3077.26 3391:3140.15 3462:1325.03 3487:1828.78 3615:3140.15 3618:1950.85 3659:4990.93 3733:3343.87 3756:1793.13 3758:6258.87 3791:1138.47 3806:2545.39 3810:2141.23 3812:3526.85 3846:2310.28 3938:1944.6 4109:4503.9 4121:4309.72 4125:6457.98 4146:2732.24 4161:3392.7 4321:1566.25 4324:2059.05 4431:-1480.4524999999999 4472:-682.12 4501:3328.61 4624:-1022.85125 4637:2157.71 4762:-1060.0900000000001 4801:3599.43 4851:1496.8 4918:-224.30000000000007 4954:1505.78 4955:2373.42 5054:-762.19 5066:-1397.07 5145:1180.04 5147:1922.33 5154:1170.64 5178:6916.98 5191:1402.02 5329:-1698.01 5374:-2030.375 5395:1797.74 5430:588.579 5550:2634.95 5591:1151.09 5694:3212.05 5741:1579.16 5752:-1824.9524999999999 5786:2505.97 5795:3295.98 5844:1643.46 5864:2599.47 5876:6286.62 5880:-2124.64 5881:-2464.305 5894:-2415.3775 5940:1364.49 5988:1819.03 6000:1932.35 6015:1529.65 6018:2686.53 6036:-1471.7224999999999 6041:2324.87 6093:4460.77 6099:2262.76 6137:3948.77 6139:4816.72 6141:2315.26 6184:992.839 6194:2134.55 6197:1597.9 6253:-2760.15 6258:3202.87 6316:3343.87 6449:1132.27 6450:285.123125 6504:6398.56 6582:1313.41 6632:-1026.8915 6659:1295.74 6661:1976.62 6707:1749.23 6720:-2214.66 6802:2673.13 6878:3455.98 6923:2366.19 7016:2202.29 7030:527.315 7063:2714.44 7086:3083.01 7140:1983.27 7170:-1348.175 7245:2588.18 7293:3048.55 7320:1929.33 7415:1197.26 7457:807.977 7573:968.259 7577:2577.14 7611:1745.04 7693:6916.98 7706:-5600.35 7760:2904.01 7791:-5395.4 7793:-174.29000000000008 7924:2286.69 7935:2808.93 7946:1716.67 8021:-2518.83 8032:1708.85 8097:-4211.525 8271:-748.18
current node ID: [0]
pred0.dat = predicted labels file
529.226 = avg Loss of solution
(127/330) = number of misclassified examples

Printing out global weights after this round of gossip.
[finish]: global weight norm at node[0]: 41046.964161224576
[finish]: global weight norm at node[1]: 25149.739472259815
[finish]: global weight norm at node[2]: 27246.786559284115
[finish]: global weight norm at node[3]: 24362.863672811334
[finish]: global weight norm at node[4]: 27414.72314804549
[finish]: global weight norm at node[5]: 12011.599070844519
[finish]: global weight norm at node[6]: 29998.507455562565
[finish]: global weight norm at node[7]: 14127.90188026453
[finish]: global weight norm at node[8]: 29505.91680478298
[finish]: global weight norm at node[9]: 21076.25869289929
Entering next cycle.
Norm: 25149.739472259815 Node ID: 1
getTrainingData
Loading modelfile
Objective Value after gossip/before training: 12122.4
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_1.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_1.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_1.dat
Objective Value after training: 12275.1
WeightVector before pushsum: 
 48:1038.79 57:-2113.64 59:416.548 75:-2410.25 87:836.305 95:-2148.2 119:-3717.19 163:-1830.2 165:-1603.14 187:-4765.87 285:-5469.65 300:435.82 358:-2296.82 485:-2831.91 494:718.545 521:865.795 523:657.875 564:434.243 589:481.882 617:-8489.93 642:456.43 672:-1796.41 677:507.11 839:-4101.15 871:2278.2 895:785.34 1008:-4944.37 1019:790.295 1077:420.413 1097:866.53 1114:410.115 1161:377.978 1163:-5698.15 1239:630.205 1371:915.03 1480:-2987.83 1496:-3612.21 1516:-2015.2 1518:612.18 1548:-6281.23 1560:-3088.32 1610:-4900.95 1665:-2913.86 1673:893.235 1712:-3417.3 1725:-2219.63 1826:1013.58 1827:307.733 1909:462.87 1910:1389.11 1916:-3630.41 1924:401.137 1944:-4790.29 1951:-2994.53 2001:-3477.65 2007:551.55 2180:1920.29 2192:-865.73 2205:1086.62 2208:732.59 2263:451.777 2279:786.66 2310:439.033 2336:-2523.41 2341:699.82 2388:-3747.41 2467:-3158.38 2494:-3506.5 2534:628.635 2572:667.765 2577:-1317.84 2597:451.91 2651:-5189.62 2656:370.777 2716:693.265 2763:405.555 2769:1286.34 2775:-2521.46 2816:575.0 2819:667.765 2855:-2721.64 2907:812.2 2935:929.32 2940:1249.44 2973:-5359.91 2982:1196.19 2996:364.168 3023:-5151.69 3088:927.325 3149:-2094.58 3161:734.615 3213:-4172.49 3217:-1531.35 3259:-1823.76 3275:443.155 3376:447.832 3415:-4064.35 3462:-1509.38 3464:-2663.68 3505:-4034.39 3528:-4349.98 3537:759.73 3654:267.507 3766:-5151.69 3780:328.803 3809:1343.03 3810:746.705 3812:1128.31 3864:-6249.89 3898:-4909.89 4010:1202.28 4074:-4305.77 4154:831.285 4197:-3786.68 4269:3021.75 4295:543.67 4324:-3073.42 4362:1236.52 4441:-1639.99 4442:-3983.56 4448:-5046.71 4453:936.39 4461:504.5 4472:-5162.17 4483:450.085 4498:834.285 4501:764.44 4628:-2374.3 4702:-3742.91 4724:491.558 4742:-5014.29 4820:476.09 4821:609.77 4844:972.345 4918:-2104.25 4954:423.652 4959:-2936.89 5009:972.345 5147:-4806.28 5201:-1372.88 5207:-6943.85 5258:612.515 5287:-6130.88 5295:631.785 5326:535.4 5370:546.245 5387:622.56 5395:-2683.38 5430:487.835 5464:705.06 5591:-2042.03 5615:829.345 5625:456.752 5632:-2778.52 5657:1273.39 5663:-2473.71 5704:-3266.36 5785:685.185 5801:-1892.53 5858:-1553.44 5958:314.975 6015:-2172.84 6036:612.71 6039:671.925 6124:-3149.03 6184:-1761.29 6233:-5101.55 6235:335.087 6411:-2784.66 6450:-1122.27 6459:-3574.56 6499:705.06 6502:811.275 6531:-5698.15 6578:-5345.12 6582:-1298.35 6586:451.777 6587:1082.72 6596:357.17 6602:-6924.63 6627:-4067.51 6638:450.89 6659:-2066.03 6660:-1889.92 6714:417.592 6734:991.22 6744:-2315.41 6766:383.627 6797:-6130.88 6891:421.485 6978:800.4 6996:652.26 7030:-2080.26 7058:835.925 7063:-4815.4 7086:-1611.23 7099:-2803.07 7105:-5080.34 7166:524.58 7189:583.77 7221:-6025.9 7244:-3084.66 7250:694.775 7366:-5632.09 7371:-3530.27 7443:-1234.24 7486:772.03 7517:751.62 7523:-2526.34 7524:-3295.58 7549:310.16 7573:-1445.26 7576:493.933 7595:-3351.78 7611:1030.36 7648:1148.19 7662:1812.22 7758:857.71 7793:-2758.51 7970:-11026.2 8027:-980.102 8064:-5656.85 8097:-1663.0 8104:-5698.15 8146:-6495.27 8153:-4067.51 8227:-2448.78 8232:-5270.7 8235:-2744.87 8271:-445.914 8276:840.395 8277:-2613.43 8279:1234.76 8281:475.957
Node 1 is gossiping with Node 9....
WeightVector after pushsum: 
 48:1038.79 57:-2113.64 59:416.548 75:-2283.6099999999997 86:-62.696875 87:836.305 95:-2148.2 119:-3717.19 138:-70.219375 163:-1830.2 165:-1603.14 187:-4765.87 254:-62.375625 285:-4718.07 300:158.75437499999998 358:-2296.82 485:-2831.91 494:-838.0574999999999 521:865.795 523:657.875 526:-107.943125 557:-68.044375 564:158.18025 567:-804.1125 589:481.882 617:-8489.93 642:-2203.48 672:-672.9512500000001 677:507.11 799:-1996.7875 839:-4101.15 871:1515.355 895:785.34 958:-76.5225 960:330.233125 969:-215.308125 971:-90.918125 1008:-2974.9631249999998 1019:790.295 1077:420.413 1097:866.53 1114:149.39125 1161:377.978 1163:-5698.15 1237:-103.12125 1239:630.205 1297:-1509.6175 1371:915.03 1404:-51.84875 1463:-150.799375 1477:-1566.4 1480:-1558.234375 1496:-3612.21 1516:-2015.2 1518:612.18 1529:-115.383125 1533:-1108.755 1548:-6281.23 1560:-3088.32 1610:-4900.95 1643:-386.179375 1646:657.025 1665:-2913.86 1673:893.235 1694:-528.095 1712:-3417.3 1725:-1157.5971875 1809:-326.39828124999997 1826:962.074375 1827:483.72024999999996 1909:462.87 1910:1389.11 1916:-3630.41 1924:401.137 1926:-138.056875 1944:-4790.29 1951:-2994.53 2001:-3477.65 2007:551.55 2051:553.535625 2054:-457.58125 2112:-103.12125 2125:-2317.4 2180:1920.29 2192:-800.35421875 2205:1086.62 2208:732.59 2263:451.777 2279:786.66 2310:439.033 2336:-2523.41 2341:699.82 2370:-104.2175 2388:-3747.41 2394:-3134.5 2447:-566.665 2467:-3158.38 2494:-3506.5 2534:628.635 2541:677.59375 2572:667.765 2577:-167.20374999999996 2597:451.91 2616:-319.469375 2622:-98.839375 2651:-5189.62 2656:-632.2636875000001 2701:-161.709375 2716:693.265 2753:-54.071875 2763:405.555 2769:1286.34 2775:-2521.46 2816:575.0 2819:667.765 2828:-3296.2 2838:-191.6140625 2855:-2721.64 2907:812.2 2935:929.32 2940:1249.44 2973:-5359.91 2982:1196.19 2990:401.10249999999996 2996:364.168 3023:-5151.69 3080:-289.6296875 3088:927.325 3149:-2094.58 3161:734.615 3213:-4172.49 3217:-1531.35 3259:-937.4641875 3275:443.155 3376:447.832 3415:-4064.35 3438:-74.986875 3462:-1509.38 3464:-2663.68 3505:-2145.131875 3528:-4349.98 3537:759.73 3549:-191.399375 3609:-94.64375 3633:-116.505625 3654:267.507 3690:-38.549375 3766:-5151.69 3780:516.84025 3791:18.473124999999982 3809:1343.03 3810:746.705 3812:1128.31 3864:-6249.89 3892:-487.88625 3898:-2157.228125 4010:1202.28 4023:-320.084375 4024:-282.351875 4046:-93.970625 4074:-4305.77 4142:-140.998125 4146:-61.625625 4148:-66.091875 4154:831.285 4155:-71.819375 4159:404.08125 4197:-3786.68 4227:-121.2425 4251:-170.374375 4269:3021.75 4288:320.833125 4295:543.67 4324:-3073.42 4338:-59.26375 4339:-81.69 4362:1236.52 4435:-134.949375 4441:-868.26 4442:-3983.56 4448:-5046.71 4453:936.39 4461:504.5 4472:-3945.325 4483:450.085 4498:729.083125 4501:311.508125 4621:500.315 4624:-2045.705 4628:-2374.3 4702:-3742.91 4724:491.558 4742:-5014.29 4748:-1097.75 4762:-503.7188125 4770:-1229.41875 4797:-145.279375 4800:-83.13875 4802:343.110625 4820:416.05625 4821:609.77 4844:972.345 4851:-96.7825 4900:-291.015625 4918:-3509.085 4954:423.652 4959:-2936.89 5009:972.345 5054:-1524.38 5066:-87.31671875 5147:-2446.498125 5191:-53.541875 5201:-1372.88 5207:-6943.85 5214:700.94375 5219:-69.283125 5256:-122.664375 5258:612.515 5287:-6130.88 5295:631.785 5326:535.4 5335:-402.1 5336:-378.415625 5370:546.245 5374:-4060.75 5387:622.56 5395:-2683.38 5430:-121.26343750000004 5464:705.06 5591:-815.986875 5615:829.345 5625:456.752 5632:-2778.52 5657:1273.39 5663:-2473.71 5675:411.7725 5704:-3266.36 5728:349.7425 5785:685.185 5801:-1892.53 5818:-58.209375 5858:-1553.44 5881:-302.4840625 5888:-92.081875 5893:223.138125 5958:-156.73312499999997 6015:-2172.84 6036:612.71 6039:671.925 6124:-3149.03 6128:342.05125 6131:-108.64125 6179:-87.09375 6184:-1761.29 6224:-70.606875 6233:-5101.55 6235:335.087 6253:-454.06062499999996 6411:-2784.66 6450:-676.3601249999999 6459:-3574.56 6499:705.06 6502:811.275 6514:-94.64375 6531:-5698.15 6574:-61.625625 6578:-5345.12 6582:-1298.35 6586:164.5669375 6587:1082.72 6596:357.17 6602:-6924.63 6627:-4067.51 6638:450.89 6659:-2066.03 6660:-1889.92 6685:-140.998125 6707:-113.10375 6714:152.11475 6720:-456.80703125 6734:991.22 6744:-2315.41 6766:383.627 6768:750.13125 6797:-6130.88 6817:-74.144375 6891:74.22375 6978:800.4 6986:-118.680625 6996:652.26 7027:277.4275 7030:-1550.3268750000002 7058:835.925 7063:-4815.4 7086:-1611.23 7099:-2803.07 7105:-5080.34 7166:524.58 7170:-2696.35 7189:583.77 7221:-6025.9 7244:-3084.66 7246:-93.6425 7250:694.775 7256:-145.933125 7319:-49.43 7362:-385.534375 7366:-5632.09 7371:-3530.27 7405:-1825.625 7415:-77.41375 7443:-825.768125 7457:-77.55625 7463:290.0375 7486:772.03 7499:-292.65875 7517:751.62 7523:-2526.34 7524:-1718.734375 7539:-82.041875 7542:-2501.75 7549:310.16 7573:-493.233125 7576:493.933 7595:-3351.78 7611:825.9993749999999 7619:-81.51625 7648:1148.19 7662:1812.22 7758:857.71 7793:-2098.8971875 7893:-101.1 7946:-65.5575 7970:-11026.2 8021:-529.915625 8027:-621.427375 8064:-5656.85 8097:-1084.924609375 8104:-5698.15 8146:-6495.27 8153:-4067.51 8227:-2448.78 8232:-5270.7 8233:-110.1175 8235:-1446.229375 8271:-317.908703125 8276:734.423125 8277:-1362.9746874999998 8279:1234.76 8281:475.957
current node ID: [1]
pred1.dat = predicted labels file
35.8741 = avg Loss of solution
(53/330) = number of misclassified examples

Printing out global weights after this round of gossip.
[finish]: global weight norm at node[0]: 41046.964161224576
[finish]: global weight norm at node[1]: 43021.147723103975
[finish]: global weight norm at node[2]: 27246.786559284115
[finish]: global weight norm at node[3]: 24362.863672811334
[finish]: global weight norm at node[4]: 27414.72314804549
[finish]: global weight norm at node[5]: 12011.599070844519
[finish]: global weight norm at node[6]: 29998.507455562565
[finish]: global weight norm at node[7]: 14127.90188026453
[finish]: global weight norm at node[8]: 29505.91680478298
[finish]: global weight norm at node[9]: 14223.117902048123
Entering next cycle.
Norm: 27246.786559284115 Node ID: 2
getTrainingData
Loading modelfile
Objective Value after gossip/before training: 2428.15
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_2.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_2.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_2.dat
Objective Value after training: 10437
WeightVector before pushsum: 
 249:-3563.92 332:-5365.59 543:-4313.93 544:-11206.0 567:-3962.4 642:-4009.2 650:-5016.85 717:-1757.61 794:-3309.13 851:-1701.2 1023:-3225.0 1061:-5169.19 1077:-4261.02 1090:-2978.54 1274:-3771.24 1299:-2544.35 1497:-2555.39 1518:-1746.18 1582:-2501.89 1725:-1700.14 1762:-1950.94 1763:-8283.52 1809:-2940.55 1834:-2488.3 1837:-5697.26 1856:-1817.86 2007:-4510.09 2009:-4892.38 2018:-5365.59 2082:-3245.08 2104:-2261.48 2125:-2704.03 2185:-6781.67 2263:-3694.24 2336:-1932.82 2546:-2164.92 2656:-1790.69 2657:-3516.82 2701:-4403.98 2836:-1969.57 2852:-2148.37 3007:-3472.76 3045:-1874.29 3069:-5316.8 3093:-4695.98 3222:-3708.18 3223:-2032.12 3259:-910.311 3275:-4491.53 3287:-4181.39 3293:-5169.19 3343:-6543.14 3549:-3245.08 3706:-2597.48 3759:-4181.39 3780:-4143.7 3846:-1854.07 3896:-2825.95 3979:-3945.96 3999:-7482.31 4214:-5849.53 4284:-2332.61 4334:-4364.53 4363:-3852.47 4488:-2985.47 4762:-1855.6 4798:-3501.81 4851:-2033.85 4918:-1611.76 5066:-1198.38 5143:-5365.59 5207:-3141.3 5208:-3418.11 5277:-5016.85 5385:-3021.22 5430:-1678.39 5472:-3036.06 5625:-5756.19 5744:-2613.45 5881:-2477.36 5893:-2882.18 5958:-5535.68 5983:-3458.68 6141:-1858.06 6253:-2774.78 6450:-710.041 6510:-5642.4 6720:-3769.62 6757:-2882.22 6811:-2824.82 6817:-4466.73 6891:-2035.58 6918:-5365.59 7234:-2281.06 7457:-1097.88 7517:-1521.18 7524:-3128.76 7729:-2589.63 7737:-7149.78 7920:-4266.83 8021:-4319.98 8122:-4323.72 8154:-3547.85 8271:-641.774 8277:-2001.77
Node 2 is gossiping with Node 3....
WeightVector after pushsum: 
 86:-250.7875 138:-280.8775 249:-3563.92 254:-249.5025 300:-236.6225 332:-5365.59 526:-431.7725 543:-4313.93 544:-11206.0 557:-272.1775 564:-235.765 567:-3962.4 642:-4009.2 650:-5016.85 672:901.015 717:-1757.61 794:-3309.13 851:-1701.2 871:1505.02 958:-306.09 960:1320.9325 969:-861.2325 971:-363.6725 1008:-176.5225 1023:-3225.0 1061:-5169.19 1077:-4261.02 1090:-2978.54 1114:-222.665 1237:-412.485 1274:-3771.24 1297:1642.53 1299:-2544.35 1404:-207.395 1463:-603.1975 1480:-257.2775 1497:-2555.39 1518:-1746.18 1529:-461.5325 1582:-2501.89 1643:-188.8975 1646:2628.1 1725:-1041.19875 1762:-1950.94 1763:-8283.52 1809:-2775.868125 1826:1821.1375 1827:1319.415 1834:-2488.3 1837:-5697.26 1856:-1817.86 1926:-552.2275 2007:-4510.09 2009:-4892.38 2018:-5365.59 2051:2214.1425 2082:-3245.08 2104:-2261.48 2112:-412.485 2125:-2704.03 2185:-6781.67 2192:-757.3518750000001 2263:-3694.24 2336:-1932.82 2370:-416.87 2541:2710.375 2546:-2164.92 2577:1966.865 2616:-549.4125 2622:-395.3575 2656:-4165.953750000001 2657:-3516.82 2701:-2848.8275 2753:-216.2875 2836:-1969.57 2838:-766.45625 2852:-2148.37 2990:2591.45 3007:-3472.76 3045:-1874.29 3069:-5316.8 3080:-1158.51875 3093:-4695.98 3222:-3708.18 3223:-2032.12 3259:-557.49225 3275:-4491.53 3287:-4181.39 3293:-5169.19 3343:-6543.14 3438:-299.9475 3505:-511.7475 3549:-2388.1375 3609:-378.575 3633:-466.0225 3690:-154.1975 3706:-2597.48 3759:-4181.39 3780:-662.0949999999998 3791:811.1175 3846:-1854.07 3896:-2825.95 3898:1190.8675 3979:-3945.96 3999:-7482.31 4023:-1280.3375 4024:-1129.4075 4046:-375.8825 4142:-563.9925 4146:-246.5025 4148:-264.3675 4155:-287.2775 4159:1616.325 4214:-5849.53 4227:-484.97 4251:-681.4975 4284:-2332.61 4288:1283.3325 4334:-4364.53 4338:-237.055 4339:-326.76 4363:-3852.47 4435:-539.7975 4441:-193.06 4488:-2985.47 4498:1247.7625 4501:-282.8475 4621:2001.26 4762:-2297.3852500000003 4797:-581.1175 4798:-3501.81 4800:-332.555 4802:1372.4425 4820:712.045 4851:-1404.0549999999998 4900:-1164.0625 4918:-1611.76 5066:-948.4568750000001 5143:-5365.59 5147:-173.4325 5191:-214.1675 5207:-3141.3 5208:-3418.11 5214:2803.775 5219:-277.1325 5256:-490.6575 5277:-5016.85 5335:-1608.4 5336:-1513.6625 5385:-3021.22 5430:-2299.9187500000003 5472:-3036.06 5591:820.1125 5625:-5756.19 5675:1647.09 5728:1398.97 5744:-2613.45 5818:-232.8375 5881:-2448.61625 5888:-368.3275 5893:-548.5374999999999 5958:-4024.7225 5983:-3458.68 6128:1368.205 6131:-434.565 6141:-1858.06 6179:-348.375 6224:-282.4275 6253:-3203.6324999999997 6450:-170.68650000000002 6510:-5642.4 6514:-378.575 6574:-246.5025 6586:-245.28625 6685:-563.9925 6707:-452.415 6714:-226.725 6720:-3712.038125 6757:-2882.22 6768:3000.525 6811:-2824.82 6817:-2529.9424999999997 6891:-1563.865 6918:-5365.59 6986:-474.7225 7027:1109.71 7030:-179.1275 7234:-2281.06 7246:-374.57 7256:-583.7325 7319:-197.72 7362:-1542.1375 7415:-309.655 7443:-159.2975 7457:26.714999999999918 7463:1160.15 7499:-334.11 7517:-1521.18 7524:-1848.1575 7539:-328.1675 7573:917.5875 7611:1243.2775 7619:-326.065 7729:-2589.63 7737:-7149.78 7793:-154.78875 7893:-404.4 7920:-4266.83 7946:-262.23 8021:-4279.6525 8027:-100.303 8097:-1013.6984375 8122:-4323.72 8154:-3547.85 8233:-440.47 8235:-295.1775 8271:-700.6938124999999 8276:1256.9025 8277:-1225.92375
current node ID: [2]
pred2.dat = predicted labels file
0.0363636 = avg Loss of solution
(12/330) = number of misclassified examples

Printing out global weights after this round of gossip.
[finish]: global weight norm at node[0]: 41046.964161224576
[finish]: global weight norm at node[1]: 43021.147723103975
[finish]: global weight norm at node[2]: 40521.502333544704
[finish]: global weight norm at node[3]: 15683.042544699958
[finish]: global weight norm at node[4]: 27414.72314804549
[finish]: global weight norm at node[5]: 12011.599070844519
[finish]: global weight norm at node[6]: 29998.507455562565
[finish]: global weight norm at node[7]: 14127.90188026453
[finish]: global weight norm at node[8]: 29505.91680478298
[finish]: global weight norm at node[9]: 14223.117902048123
Entering next cycle.
Norm: 15683.042544699958 Node ID: 3
getTrainingData
Loading modelfile
Objective Value after gossip/before training: 12543.6
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_3.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_3.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_3.dat
Objective Value after training: 3289.72
WeightVector before pushsum: 
 86:-501.575 138:-561.755 254:-499.005 300:-473.245 526:-863.545 557:-544.355 564:-471.53 672:1802.03 871:3010.04 958:-612.18 960:2641.86 969:-1722.46 971:-727.345 1008:-353.045 1114:-445.33 1237:-824.97 1297:3285.06 1404:-414.79 1463:-1206.39 1480:-514.555 1529:-923.065 1643:-377.795 1646:5256.2 1725:-382.257 1826:3642.28 1827:2638.83 1926:-1104.45 2051:4428.28 2112:-824.97 2192:-232.185 2370:-833.74 2541:5420.75 2577:3933.73 2616:-1098.83 2622:-790.715 2656:-402.618 2753:-432.575 2990:5182.9 3259:-204.673 3438:-599.895 3505:-1023.5 3549:-1531.19 3609:-757.15 3633:-932.045 3690:-308.395 3780:2819.51 3791:1622.23 3898:2381.74 4023:-2560.68 4024:-2258.82 4046:-751.765 4142:-1127.98 4146:-493.005 4148:-528.735 4155:-574.555 4159:3232.65 4227:-969.94 4251:-1362.99 4288:2566.66 4338:-474.11 4339:-653.52 4435:-1079.6 4441:-386.12 4498:2495.53 4501:-565.695 4621:4002.52 4762:-210.254 4797:-1162.23 4800:-665.11 4802:2744.89 4820:1424.09 4851:-774.26 4900:-2328.12 5147:-346.865 5191:-428.335 5214:5607.55 5219:-554.265 5256:-981.315 5335:-3216.8 5336:-3027.32 5430:-179.817 5591:1640.22 5675:3294.18 5728:2797.94 5818:-465.675 5888:-736.655 5893:1785.11 5958:2700.93 6128:2736.41 6131:-869.13 6179:-696.75 6224:-564.855 6450:368.668 6514:-757.15 6574:-493.005 6586:-490.572 6685:-1127.98 6707:-904.83 6714:-453.45 6768:6001.05 6817:-593.155 6891:-1092.15 6986:-949.445 7027:2219.42 7030:-358.255 7246:-749.14 7256:-1167.46 7319:-395.44 7362:-3084.28 7415:-619.31 7443:-318.595 7457:1151.31 7463:2320.3 7499:-668.22 7524:-567.555 7539:-656.335 7573:1835.17 7611:2486.55 7619:-652.13 7793:-309.577 7893:-808.8 7946:-524.46 8027:-200.606 8233:-880.94 8235:-590.355 8271:673.01 8276:2513.8 8277:-450.077
Node 3 is gossiping with Node 1....
WeightVector after pushsum: 
 48:519.395 57:-1056.82 59:208.274 75:-1141.8049999999998 86:-282.1359375 87:418.1525 95:-1074.1 119:-1858.595 138:-315.9871875 163:-915.1 165:-801.57 187:-2382.935 254:-280.6903125 285:-2359.035 300:-157.2453125 358:-1148.41 485:-1415.955 494:-419.02874999999995 521:432.8975 523:328.9375 526:-485.7440625 557:-306.1996875 564:-156.674875 567:-402.05625 589:240.941 617:-4244.965 642:-1101.74 672:564.539375 677:253.555 799:-998.39375 839:-2050.575 871:2262.6975 895:392.67 958:-344.35125 960:1486.0465625000002 969:-968.8840625 971:-409.13156250000003 1008:-1664.0040625 1019:395.1475 1077:210.2065 1097:433.265 1114:-147.96937499999999 1161:188.989 1163:-2849.075 1237:-464.04562500000003 1239:315.1025 1297:887.7212499999999 1371:457.515 1404:-233.319375 1463:-678.5946875000001 1477:-783.2 1480:-1036.3946875 1496:-1806.105 1516:-1007.6 1518:306.09 1529:-519.2240625000001 1533:-554.3775 1548:-3140.615 1560:-1544.16 1610:-2450.475 1643:-381.9871875 1646:2956.6124999999997 1665:-1456.93 1673:446.6175 1694:-264.0475 1712:-1708.65 1725:-769.92709375 1809:-163.19914062499998 1826:2302.1771875 1827:1561.275125 1909:231.435 1910:694.555 1916:-1815.205 1924:200.5685 1926:-621.2534375 1944:-2395.145 1951:-1497.265 2001:-1738.825 2007:275.775 2051:2490.9078124999996 2054:-228.790625 2112:-464.04562500000003 2125:-1158.7 2180:960.145 2192:-516.269609375 2205:543.31 2208:366.295 2263:225.8885 2279:393.33 2310:219.5165 2336:-1261.705 2341:349.91 2370:-468.97875 2388:-1873.705 2394:-1567.25 2447:-283.3325 2467:-1579.19 2494:-1753.25 2534:314.3175 2541:3049.171875 2572:333.8825 2577:1883.263125 2597:225.955 2616:-709.1496875 2622:-444.7771875 2651:-2594.81 2656:-517.44084375 2701:-80.8546875 2716:346.6325 2753:-243.32343749999998 2763:202.7775 2769:643.17 2775:-1260.73 2816:287.5 2819:333.8825 2828:-1648.1 2838:-95.80703125 2855:-1360.82 2907:406.1 2935:464.66 2940:624.72 2973:-2679.955 2982:598.095 2990:2792.00125 2996:182.084 3023:-2575.845 3080:-144.81484375 3088:463.6625 3149:-1047.29 3161:367.3075 3213:-2086.245 3217:-765.675 3259:-571.06859375 3275:221.5775 3376:223.916 3415:-2032.175 3438:-337.4409375 3462:-754.69 3464:-1331.84 3505:-1584.3159375 3528:-2174.99 3537:379.865 3549:-861.2946875 3609:-425.89687499999997 3633:-524.2753124999999 3654:133.7535 3690:-173.4721875 3766:-2575.845 3780:1668.1751250000002 3791:820.3515625 3809:671.515 3810:373.3525 3812:564.155 3864:-3124.945 3892:-243.943125 3898:112.25593749999985 4010:601.14 4023:-1440.3821874999999 4024:-1270.5859375 4046:-422.8678125 4074:-2152.885 4142:-634.4890625 4146:-277.3153125 4148:-297.4134375 4154:415.6425 4155:-323.1871875 4159:1818.3656250000001 4197:-1893.34 4227:-545.5912500000001 4251:-766.6821875 4269:1510.875 4288:1443.7465625 4295:271.835 4324:-1536.71 4338:-266.686875 4339:-367.605 4362:618.26 4435:-607.2746874999999 4441:-627.19 4442:-1991.78 4448:-2523.355 4453:468.195 4461:252.25 4472:-1972.6625 4483:225.0425 4498:1612.3065625000002 4501:-127.09343750000002 4621:2251.4175 4624:-1022.8525 4628:-1187.15 4702:-1871.455 4724:245.779 4742:-2507.145 4748:-548.875 4762:-356.98640625 4770:-614.709375 4797:-653.7546875 4800:-374.124375 4802:1544.0003124999998 4820:920.0731249999999 4821:304.885 4844:486.1725 4851:-435.52125 4900:-1309.5678125 4918:-1754.5425 4954:211.826 4959:-1468.445 5009:486.1725 5054:-762.19 5066:-43.658359375 5147:-1396.6815625 5191:-240.9384375 5201:-686.44 5207:-3471.925 5214:3154.2468750000003 5219:-311.7740625 5256:-551.9896875000001 5258:306.2575 5287:-3065.44 5295:315.8925 5326:267.7 5335:-1809.45 5336:-1702.8678125000001 5370:273.1225 5374:-2030.375 5387:311.28 5395:-1341.69 5430:-150.54021875 5464:352.53 5591:412.1165625 5615:414.6725 5625:228.376 5632:-1389.26 5657:636.695 5663:-1236.855 5675:1852.97625 5704:-1633.18 5728:1573.84125 5785:342.5925 5801:-946.265 5818:-261.9421875 5858:-776.72 5881:-151.24203125 5888:-414.36843749999997 5893:1004.1240624999999 5958:1272.0984374999998 6015:-1086.42 6036:306.355 6039:335.9625 6124:-1574.515 6128:1539.230625 6131:-488.885625 6179:-391.921875 6184:-880.645 6224:-317.7309375 6233:-2550.775 6235:167.5435 6253:-227.03031249999998 6411:-1392.33 6450:-153.84606249999996 6459:-1787.28 6499:352.53 6502:405.6375 6514:-425.89687499999997 6531:-2849.075 6574:-277.3153125 6578:-2672.56 6582:-649.175 6586:-163.00253125 6587:541.36 6596:178.585 6602:-3462.315 6627:-2033.755 6638:225.445 6659:-1033.015 6660:-944.96 6685:-634.4890625 6707:-508.966875 6714:-150.667625 6720:-228.403515625 6734:495.61 6744:-1157.705 6766:191.8135 6768:3375.5906250000003 6797:-3065.44 6817:-333.64968749999997 6891:-508.96312500000005 6978:400.2 6986:-534.0628125000001 6996:326.13 7027:1248.42375 7030:-954.2909375000002 7058:417.9625 7063:-2407.7 7086:-805.615 7099:-1401.535 7105:-2540.17 7166:262.29 7170:-1348.175 7189:291.885 7221:-3012.95 7244:-1542.33 7246:-421.39125 7250:347.3875 7256:-656.6965625 7319:-222.435 7362:-1734.9071875000002 7366:-2816.045 7371:-1765.135 7405:-912.8125 7415:-348.36187499999994 7443:-572.1815625 7457:536.8768749999999 7463:1305.16875 7486:386.015 7499:-480.43937500000004 7517:375.81 7523:-1263.17 7524:-1143.1446875 7539:-369.1884375 7542:-1250.875 7549:155.08 7573:670.9684375 7576:246.9665 7595:-1675.89 7611:1656.2746875 7619:-366.823125 7648:574.095 7662:906.11 7758:428.855 7793:-1204.23709375 7893:-454.95 7946:-295.00875 7970:-5513.1 8021:-264.9578125 8027:-411.0166875 8064:-2828.425 8097:-542.4623046875 8104:-2849.075 8146:-3247.635 8153:-2033.755 8227:-1224.39 8232:-2635.35 8233:-495.52875000000006 8235:-1018.2921875 8271:177.5506484375 8276:1624.1115625000002 8277:-906.5258437499999 8279:617.38 8281:237.9785
current node ID: [3]
pred3.dat = predicted labels file
335.634 = avg Loss of solution
(227/330) = number of misclassified examples

Printing out global weights after this round of gossip.
[finish]: global weight norm at node[0]: 41046.964161224576
[finish]: global weight norm at node[1]: 24604.391015088477
[finish]: global weight norm at node[2]: 40521.502333544704
[finish]: global weight norm at node[3]: 24604.391015088477
[finish]: global weight norm at node[4]: 27414.72314804549
[finish]: global weight norm at node[5]: 12011.599070844519
[finish]: global weight norm at node[6]: 29998.507455562565
[finish]: global weight norm at node[7]: 14127.90188026453
[finish]: global weight norm at node[8]: 29505.91680478298
[finish]: global weight norm at node[9]: 14223.117902048123
Entering next cycle.
Norm: 27414.72314804549 Node ID: 4
getTrainingData
Loading modelfile
Objective Value after gossip/before training: 2435.31
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_4.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_4.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_4.dat
Objective Value after training: 10376.3
WeightVector before pushsum: 
 59:-903.295 146:-1398.91 147:-3097.45 300:-945.085 876:-1337.4 1516:-409.34 1533:-852.2 1616:-1703.38 1743:-4480.25 2082:-1457.08 2155:-14246.5 2192:-273.858 2279:-812.865 2314:-819.65 2546:-972.07 2576:-1325.26 2597:-979.98 3259:-408.74 3618:-1190.24 3661:-619.725 3791:-1176.06 3812:-1025.34 3897:-9496.73 4501:-6034.58 5201:-998.4 5292:-27007.6 5310:-1496.06 5430:-359.103 5776:-1017.61 5843:-1759.28 6235:-726.645 6329:-2533.5 6387:-1713.78 6449:-7744.17 6450:-318.817 6459:-1158.14 6596:-774.53 6748:-1235.59 6817:-1184.55 6839:-1639.1 6893:-2525.62 7086:-6595.16 7163:-890.06 7573:-6622.4 7575:-2072.45 7765:-1233.38 7793:-618.235 7898:-1448.07 7913:-898.82 8229:-1439.31 8278:-17205.0
Node 4 is gossiping with Node 5....
WeightVector after pushsum: 
 59:-903.295 86:-62.696875 138:-70.219375 146:-1398.91 147:-3097.45 254:-62.375625 300:-531.698125 526:-107.943125 557:-68.044375 564:-58.94125 567:-804.1125 672:225.25375 799:-1996.7875 871:376.255 876:-1337.4 958:-76.5225 960:330.233125 969:-215.308125 971:-90.918125 1008:-502.778125 1114:-55.66625 1237:-103.12125 1297:-1509.6175 1404:-51.84875 1463:-150.799375 1480:-64.319375 1516:-409.34 1529:-115.383125 1533:-852.2 1616:-1703.38 1643:-386.179375 1646:657.025 1694:-528.095 1725:-47.7821875 1743:-4480.25 1809:-326.39828124999997 1826:455.284375 1827:329.85375 1926:-138.056875 2051:553.535625 2054:-457.58125 2082:-1457.08 2112:-103.12125 2125:-2317.4 2155:-14246.5 2192:-504.41821875000005 2279:-812.865 2314:-819.65 2370:-104.2175 2447:-566.665 2541:677.59375 2546:-972.07 2576:-1325.26 2577:491.71625 2597:-979.98 2616:-319.469375 2622:-98.839375 2656:-817.6521875000001 2701:-161.709375 2753:-54.071875 2838:-191.6140625 2990:401.10249999999996 3080:-289.6296875 3259:-229.9541875 3438:-74.986875 3505:-127.936875 3549:-191.399375 3609:-94.64375 3618:-1190.24 3633:-116.505625 3661:-619.725 3690:-38.549375 3780:352.43875 3791:-569.556875 3812:-1025.34 3892:-487.88625 3897:-9496.73 3898:297.716875 4023:-320.084375 4024:-282.351875 4046:-93.970625 4142:-140.998125 4146:-61.625625 4148:-66.091875 4155:-71.819375 4159:404.08125 4227:-121.2425 4251:-170.374375 4288:320.833125 4338:-59.26375 4339:-81.69 4435:-134.949375 4441:-48.265 4498:311.940625 4501:-3088.001875 4621:500.315 4748:-1097.75 4762:-503.7188125 4770:-1229.41875 4797:-145.279375 4800:-83.13875 4802:343.110625 4820:178.01125 4851:-96.7825 4900:-291.015625 5066:-87.31671875 5147:-43.358125 5191:-53.541875 5201:-998.4 5214:700.94375 5219:-69.283125 5256:-122.664375 5292:-27007.6 5310:-1496.06 5335:-402.1 5336:-378.415625 5430:-544.7324375000001 5591:205.028125 5675:411.7725 5728:349.7425 5776:-1017.61 5818:-58.209375 5843:-1759.28 5881:-302.4840625 5888:-92.081875 5893:223.138125 5958:-314.220625 6128:342.05125 6131:-108.64125 6179:-87.09375 6224:-70.606875 6235:-726.645 6253:-454.06062499999996 6329:-2533.5 6387:-1713.78 6449:-7744.17 6450:-274.633625 6459:-1158.14 6514:-94.64375 6574:-61.625625 6586:-61.3215625 6596:-774.53 6685:-140.998125 6707:-113.10375 6714:-56.68125 6720:-456.80703125 6748:-1235.59 6768:750.13125 6817:-666.419375 6839:-1639.1 6891:-136.51875 6893:-2525.62 6986:-118.680625 7027:277.4275 7030:-510.19687500000003 7086:-6595.16 7163:-890.06 7246:-93.6425 7256:-145.933125 7319:-49.43 7362:-385.534375 7405:-1825.625 7415:-77.41375 7443:-208.648125 7457:-77.55625 7463:290.0375 7499:-292.65875 7524:-70.944375 7539:-82.041875 7542:-2501.75 7573:-3081.803125 7575:-2072.45 7611:310.819375 7619:-81.51625 7765:-1233.38 7793:-1028.7596875000002 7893:-101.1 7898:-1448.07 7913:-898.82 7946:-65.5575 8021:-529.915625 8027:-131.376375 8097:-253.424609375 8229:-1439.31 8233:-110.1175 8235:-73.794375 8271:-94.951703125 8276:314.225625 8277:-56.2596875 8278:-17205.0
current node ID: [4]
pred4.dat = predicted labels file
0.133333 = avg Loss of solution
(44/330) = number of misclassified examples

Printing out global weights after this round of gossip.
[finish]: global weight norm at node[0]: 41046.964161224576
[finish]: global weight norm at node[1]: 24604.391015088477
[finish]: global weight norm at node[2]: 40521.502333544704
[finish]: global weight norm at node[3]: 24604.391015088477
[finish]: global weight norm at node[4]: 39603.36572875622
[finish]: global weight norm at node[5]: 7551.47298504226
[finish]: global weight norm at node[6]: 29998.507455562565
[finish]: global weight norm at node[7]: 14127.90188026453
[finish]: global weight norm at node[8]: 29505.91680478298
[finish]: global weight norm at node[9]: 14223.117902048123
Entering next cycle.
Norm: 7551.47298504226 Node ID: 5
getTrainingData
Loading modelfile
Objective Value after gossip/before training: 12237
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_5.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_5.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_5.dat
Objective Value after training: 12872.3
WeightVector before pushsum: 
 86:-3705.86 567:-3216.45 799:-7987.15 1227:-5893.72 1312:-12429.7 1499:-5701.19 1508:-3638.91 1593:-4711.06 1694:-948.05 1809:-1747.39 1856:-3019.84 1974:-7952.44 2054:-1830.33 2125:-9269.6 2155:-4701.8 2192:-580.235 2447:-2266.66 2466:-4546.91 2546:-3596.38 2605:-6508.77 2609:-9689.33 2656:-6138.6 2669:-7492.19 2700:-6603.34 2907:-3848.58 2935:-4403.54 3881:-11180.4 3892:-1951.55 4722:-3333.61 4748:-4391.0 4762:-1735.28 4770:-4917.68 4832:-4523.03 5147:-2562.79 5154:-2642.44 5370:-4382.48 5430:-2741.63 5591:-2598.3 5632:-5986.0 5664:-3528.85 5724:-3106.78 5744:-4341.48 5782:-8334.04 5801:-3007.35 5810:-6004.45 5881:-1187.72 5958:-5214.7 6252:-4106.0 6253:-2252.41 6449:-2555.82 6450:-1037.33 6607:-6264.81 6720:-2547.12 6875:-4538.9 6891:-5725.41 7320:-4354.98 7323:-3378.64 7355:-2781.09 7364:-6421.49 7405:-7302.5 7411:-6340.45 7443:-2353.93 7457:-1823.81 7542:-10007.0 7573:-4586.73 7878:-4711.06 7880:-7547.94 7934:-5324.99 8021:-2672.72 8068:-7554.34 8271:-610.55 8281:-3818.56
Node 5 is gossiping with Node 3....
WeightVector after pushsum: 
 48:259.6975 57:-528.41 59:104.137 75:-570.9024999999999 86:-1993.9979687500002 87:209.07625 95:-537.05 119:-929.2975 138:-157.99359375 163:-457.55 165:-400.785 187:-1191.4675 254:-140.34515625 285:-1179.5175 300:-78.62265625 358:-574.205 485:-707.9775 494:-209.51437499999997 521:216.44875 523:164.46875 526:-242.87203125 557:-153.09984375 564:-78.3374375 567:-1809.253125 589:120.4705 617:-2122.4825 642:-550.87 672:282.2696875 677:126.7775 799:-4492.771874999999 839:-1025.2875 871:1131.34875 895:196.335 958:-172.175625 960:743.0232812500001 969:-484.44203125 971:-204.56578125000001 1008:-832.00203125 1019:197.57375 1077:105.10325 1097:216.6325 1114:-73.98468749999999 1161:94.4945 1163:-1424.5375 1227:-5893.72 1237:-232.02281250000001 1239:157.55125 1297:443.86062499999997 1312:-12429.7 1371:228.7575 1404:-116.6596875 1463:-339.29734375000004 1477:-391.6 1480:-518.19734375 1496:-903.0525 1499:-5701.19 1508:-3638.91 1516:-503.8 1518:153.045 1529:-259.61203125000003 1533:-277.18875 1548:-1570.3075 1560:-772.08 1593:-4711.06 1610:-1225.2375 1643:-190.99359375 1646:1478.3062499999999 1665:-728.465 1673:223.30875 1694:-606.0487499999999 1712:-854.325 1725:-384.963546875 1809:-955.2945703125 1826:1151.08859375 1827:780.6375625 1856:-3019.84 1909:115.7175 1910:347.2775 1916:-907.6025 1924:100.28425 1926:-310.62671875 1944:-1197.5725 1951:-748.6325 1974:-7952.44 2001:-869.4125 2007:137.8875 2051:1245.4539062499998 2054:-1029.5603125 2112:-232.02281250000001 2125:-5214.150000000001 2155:-4701.8 2180:480.0725 2192:-548.2523046875 2205:271.655 2208:183.1475 2263:112.94425 2279:196.665 2310:109.75825 2336:-630.8525 2341:174.955 2370:-234.489375 2388:-936.8525 2394:-783.625 2447:-1274.99625 2466:-4546.91 2467:-789.595 2494:-876.625 2534:157.15875 2541:1524.5859375 2546:-3596.38 2572:166.94125 2577:941.6315625 2597:112.9775 2605:-6508.77 2609:-9689.33 2616:-354.57484375 2622:-222.38859375 2651:-1297.405 2656:-3328.020421875 2669:-7492.19 2700:-6603.34 2701:-40.42734375 2716:173.31625 2753:-121.66171874999999 2763:101.38875 2769:321.585 2775:-630.365 2816:143.75 2819:166.94125 2828:-824.05 2838:-47.903515625 2855:-680.41 2907:-1721.24 2935:-1969.44 2940:312.36 2973:-1339.9775 2982:299.0475 2990:1396.000625 2996:91.042 3023:-1287.9225 3080:-72.407421875 3088:231.83125 3149:-523.645 3161:183.65375 3213:-1043.1225 3217:-382.8375 3259:-285.534296875 3275:110.78875 3376:111.958 3415:-1016.0875 3438:-168.72046875 3462:-377.345 3464:-665.92 3505:-792.15796875 3528:-1087.495 3537:189.9325 3549:-430.64734375 3609:-212.94843749999998 3633:-262.13765624999996 3654:66.87675 3690:-86.73609375 3766:-1287.9225 3780:834.0875625000001 3791:410.17578125 3809:335.7575 3810:186.67625 3812:282.0775 3864:-1562.4725 3881:-11180.4 3892:-1097.7465625 3898:56.12796874999992 4010:300.57 4023:-720.1910937499999 4024:-635.29296875 4046:-211.43390625 4074:-1076.4425 4142:-317.24453125 4146:-138.65765625 4148:-148.70671875 4154:207.82125 4155:-161.59359375 4159:909.1828125000001 4197:-946.67 4227:-272.79562500000003 4251:-383.34109375 4269:755.4375 4288:721.87328125 4295:135.9175 4324:-768.355 4338:-133.3434375 4339:-183.8025 4362:309.13 4435:-303.63734374999996 4441:-313.595 4442:-995.89 4448:-1261.6775 4453:234.0975 4461:126.125 4472:-986.33125 4483:112.52125 4498:806.1532812500001 4501:-63.54671875000001 4621:1125.70875 4624:-511.42625 4628:-593.575 4702:-935.7275 4722:-3333.61 4724:122.8895 4742:-1253.5725 4748:-2469.9375 4762:-1046.133203125 4770:-2766.1946875000003 4797:-326.87734375 4800:-187.0621875 4802:772.0001562499999 4820:460.03656249999995 4821:152.4425 4832:-4523.03 4844:243.08625 4851:-217.760625 4900:-654.78390625 4918:-877.27125 4954:105.913 4959:-734.2225 5009:243.08625 5054:-381.095 5066:-21.8291796875 5147:-1979.73578125 5154:-2642.44 5191:-120.46921875 5201:-343.22 5207:-1735.9625 5214:1577.1234375000001 5219:-155.88703125 5256:-275.99484375000003 5258:153.12875 5287:-1532.72 5295:157.94625 5326:133.85 5335:-904.725 5336:-851.4339062500001 5370:-2054.6787499999996 5374:-1015.1875 5387:155.64 5395:-670.845 5430:-1446.085109375 5464:176.265 5591:-1093.0917187500002 5615:207.33625 5625:114.188 5632:-3687.63 5657:318.3475 5663:-618.4275 5664:-3528.85 5675:926.488125 5704:-816.59 5724:-3106.78 5728:786.920625 5744:-4341.48 5782:-8334.04 5785:171.29625 5801:-1976.8075 5810:-6004.45 5818:-130.97109375 5858:-388.36 5881:-669.481015625 5888:-207.18421874999999 5893:502.06203124999996 5958:-1971.30078125 6015:-543.21 6036:153.1775 6039:167.98125 6124:-787.2575 6128:769.6153125 6131:-244.4428125 6179:-195.9609375 6184:-440.3225 6224:-158.86546875 6233:-1275.3875 6235:83.77175 6252:-4106.0 6253:-1239.72015625 6411:-696.165 6449:-2555.82 6450:-595.58803125 6459:-893.64 6499:176.265 6502:202.81875 6514:-212.94843749999998 6531:-1424.5375 6574:-138.65765625 6578:-1336.28 6582:-324.5875 6586:-81.501265625 6587:270.68 6596:89.2925 6602:-1731.1575 6607:-6264.81 6627:-1016.8775 6638:112.7225 6659:-516.5075 6660:-472.48 6685:-317.24453125 6707:-254.4834375 6714:-75.3338125 6720:-1387.7617578125 6734:247.805 6744:-578.8525 6766:95.90675 6768:1687.7953125000001 6797:-1532.72 6817:-166.82484374999999 6875:-4538.9 6891:-3117.1865625 6978:200.1 6986:-267.03140625000003 6996:163.065 7027:624.211875 7030:-477.1454687500001 7058:208.98125 7063:-1203.85 7086:-402.8075 7099:-700.7675 7105:-1270.085 7166:131.145 7170:-674.0875 7189:145.9425 7221:-1506.475 7244:-771.165 7246:-210.695625 7250:173.69375 7256:-328.34828125 7319:-111.2175 7320:-4354.98 7323:-3378.64 7355:-2781.09 7362:-867.4535937500001 7364:-6421.49 7366:-1408.0225 7371:-882.5675 7405:-4107.65625 7411:-6340.45 7415:-174.18093749999997 7443:-1463.0557812499999 7457:-643.4665625 7463:652.584375 7486:193.0075 7499:-240.21968750000002 7517:187.905 7523:-631.585 7524:-571.57234375 7539:-184.59421875 7542:-5628.9375 7549:77.54 7573:-1957.8807812499997 7576:123.48325 7595:-837.945 7611:828.13734375 7619:-183.4115625 7648:287.0475 7662:453.055 7758:214.4275 7793:-602.118546875 7878:-4711.06 7880:-7547.94 7893:-227.475 7934:-5324.99 7946:-147.504375 7970:-2756.55 8021:-1468.8389062499998 8027:-205.50834375 8064:-1414.2125 8068:-7554.34 8097:-271.23115234375 8104:-1424.5375 8146:-1623.8175 8153:-1016.8775 8227:-612.195 8232:-1317.675 8233:-247.76437500000003 8235:-509.14609375 8271:-216.49967578124998 8276:812.0557812500001 8277:-453.26292187499996 8279:308.69 8281:-1790.29075
current node ID: [5]
pred5.dat = predicted labels file
0.0151515 = avg Loss of solution
(5/330) = number of misclassified examples

Printing out global weights after this round of gossip.
[finish]: global weight norm at node[0]: 41046.964161224576
[finish]: global weight norm at node[1]: 24604.391015088477
[finish]: global weight norm at node[2]: 40521.502333544704
[finish]: global weight norm at node[3]: 18642.346990983202
[finish]: global weight norm at node[4]: 39603.36572875622
[finish]: global weight norm at node[5]: 40573.0191221669
[finish]: global weight norm at node[6]: 29998.507455562565
[finish]: global weight norm at node[7]: 14127.90188026453
[finish]: global weight norm at node[8]: 29505.91680478298
[finish]: global weight norm at node[9]: 14223.117902048123
Entering next cycle.
Norm: 29998.507455562565 Node ID: 6
getTrainingData
Loading modelfile
Objective Value after gossip/before training: 2435.23
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_6.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_6.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_6.dat
Objective Value after training: 612.093
WeightVector before pushsum: 
 567:-2629.07 1809:-1487.06 2092:-4113.12 2192:-1111.37 2496:-1469.68 2581:-1181.97 2627:-1344.32 2996:-970.385 3654:-1206.9 3656:-1202.65 3690:-756.78 3810:-948.11 4353:-712.495 4762:-938.39 4861:-2528.85 5066:-661.195 5201:-2134.54 5742:-4207.82 5881:-1643.74 6253:-1841.08 6582:-984.675 6720:-1906.32 7820:-2960.4 8021:-1898.97 8125:-1504.87 8271:-354.092
Node 6 is gossiping with Node 5....
WeightVector after pushsum: 
 48:129.84875 57:-264.205 59:52.0685 75:-285.45124999999996 86:-996.9989843750001 87:104.538125 95:-268.525 119:-464.64875 138:-78.996796875 163:-228.775 165:-200.3925 187:-595.73375 254:-70.172578125 285:-589.75875 300:-39.311328125 358:-287.1025 485:-353.98875 494:-104.75718749999999 521:108.224375 523:82.234375 526:-121.436015625 557:-76.549921875 564:-39.16871875 567:-2219.1615625 589:60.23525 617:-1061.24125 642:-275.435 672:141.13484375 677:63.38875 799:-2246.3859374999997 839:-512.64375 871:565.674375 895:98.1675 958:-86.0878125 960:371.51164062500004 969:-242.221015625 971:-102.28289062500001 1008:-416.001015625 1019:98.786875 1077:52.551625 1097:108.31625 1114:-36.992343749999996 1161:47.24725 1163:-712.26875 1227:-2946.86 1237:-116.01140625000001 1239:78.775625 1297:221.93031249999999 1312:-6214.85 1371:114.37875 1404:-58.32984375 1463:-169.64867187500002 1477:-195.8 1480:-259.098671875 1496:-451.52625 1499:-2850.595 1508:-1819.455 1516:-251.9 1518:76.5225 1529:-129.80601562500001 1533:-138.594375 1548:-785.15375 1560:-386.04 1593:-2355.53 1610:-612.61875 1643:-95.496796875 1646:739.1531249999999 1665:-364.2325 1673:111.654375 1694:-303.02437499999996 1712:-427.1625 1725:-192.4817734375 1809:-1221.17728515625 1826:575.544296875 1827:390.31878125 1856:-1509.92 1909:57.85875 1910:173.63875 1916:-453.80125 1924:50.142125 1926:-155.313359375 1944:-598.78625 1951:-374.31625 1974:-3976.22 2001:-434.70625 2007:68.94375 2051:622.7269531249999 2054:-514.78015625 2092:-4113.12 2112:-116.01140625000001 2125:-2607.0750000000003 2155:-2350.9 2180:240.03625 2192:-829.8111523437499 2205:135.8275 2208:91.57375 2263:56.472125 2279:98.3325 2310:54.879125 2336:-315.42625 2341:87.4775 2370:-117.2446875 2388:-468.42625 2394:-391.8125 2447:-637.498125 2466:-2273.455 2467:-394.7975 2494:-438.3125 2496:-1469.68 2534:78.579375 2541:762.29296875 2546:-1798.19 2572:83.470625 2577:470.81578125 2581:-1181.97 2597:56.48875 2605:-3254.385 2609:-4844.665 2616:-177.287421875 2622:-111.194296875 2627:-1344.32 2651:-648.7025 2656:-1664.0102109375 2669:-3746.095 2700:-3301.67 2701:-20.213671875 2716:86.658125 2753:-60.830859374999996 2763:50.694375 2769:160.7925 2775:-315.1825 2816:71.875 2819:83.470625 2828:-412.025 2838:-23.9517578125 2855:-340.205 2907:-860.62 2935:-984.72 2940:156.18 2973:-669.98875 2982:149.52375 2990:698.0003125 2996:-439.6715 3023:-643.96125 3080:-36.2037109375 3088:115.915625 3149:-261.8225 3161:91.826875 3213:-521.56125 3217:-191.41875 3259:-142.7671484375 3275:55.394375 3376:55.979 3415:-508.04375 3438:-84.360234375 3462:-188.6725 3464:-332.96 3505:-396.078984375 3528:-543.7475 3537:94.96625 3549:-215.323671875 3609:-106.47421874999999 3633:-131.06882812499998 3654:-570.0116250000001 3656:-1202.65 3690:-421.758046875 3766:-643.96125 3780:417.04378125000005 3791:205.087890625 3809:167.87875 3810:-380.716875 3812:141.03875 3864:-781.23625 3881:-5590.2 3892:-548.87328125 3898:28.06398437499996 4010:150.285 4023:-360.09554687499997 4024:-317.646484375 4046:-105.716953125 4074:-538.22125 4142:-158.622265625 4146:-69.328828125 4148:-74.353359375 4154:103.910625 4155:-80.796796875 4159:454.59140625000003 4197:-473.335 4227:-136.39781250000001 4251:-191.670546875 4269:377.71875 4288:360.936640625 4295:67.95875 4324:-384.1775 4338:-66.67171875 4339:-91.90125 4353:-712.495 4362:154.565 4435:-151.81867187499998 4441:-156.7975 4442:-497.945 4448:-630.83875 4453:117.04875 4461:63.0625 4472:-493.165625 4483:56.260625 4498:403.07664062500004 4501:-31.773359375000005 4621:562.854375 4624:-255.713125 4628:-296.7875 4702:-467.86375 4722:-1666.805 4724:61.44475 4742:-626.78625 4748:-1234.96875 4762:-992.2616015624999 4770:-1383.0973437500002 4797:-163.438671875 4800:-93.53109375 4802:386.00007812499996 4820:230.01828124999997 4821:76.22125 4832:-2261.515 4844:121.543125 4851:-108.8803125 4861:-2528.85 4900:-327.391953125 4918:-438.635625 4954:52.9565 4959:-367.11125 5009:121.543125 5054:-190.5475 5066:-341.51208984375 5147:-989.867890625 5154:-1321.22 5191:-60.234609375 5201:-1238.88 5207:-867.98125 5214:788.5617187500001 5219:-77.943515625 5256:-137.99742187500001 5258:76.564375 5287:-766.36 5295:78.973125 5326:66.925 5335:-452.3625 5336:-425.71695312500003 5370:-1027.3393749999998 5374:-507.59375 5387:77.82 5395:-335.4225 5430:-723.0425546875 5464:88.1325 5591:-546.5458593750001 5615:103.668125 5625:57.094 5632:-1843.815 5657:159.17375 5663:-309.21375 5664:-1764.425 5675:463.2440625 5704:-408.295 5724:-1553.39 5728:393.4603125 5742:-4207.82 5744:-2170.74 5782:-4167.02 5785:85.648125 5801:-988.40375 5810:-3002.225 5818:-65.485546875 5858:-194.18 5881:-1156.6105078125001 5888:-103.59210937499999 5893:251.03101562499998 5958:-985.650390625 6015:-271.605 6036:76.58875 6039:83.990625 6124:-393.62875 6128:384.80765625 6131:-122.22140625 6179:-97.98046875 6184:-220.16125 6224:-79.432734375 6233:-637.69375 6235:41.885875 6252:-2053.0 6253:-1540.400078125 6411:-348.0825 6449:-1277.91 6450:-297.794015625 6459:-446.82 6499:88.1325 6502:101.409375 6514:-106.47421874999999 6531:-712.26875 6574:-69.328828125 6578:-668.14 6582:-654.6312499999999 6586:-40.7506328125 6587:135.34 6596:44.64625 6602:-865.57875 6607:-3132.405 6627:-508.43875 6638:56.36125 6659:-258.25375 6660:-236.24 6685:-158.622265625 6707:-127.24171875 6714:-37.66690625 6720:-1647.0408789062499 6734:123.9025 6744:-289.42625 6766:47.953375 6768:843.8976562500001 6797:-766.36 6817:-83.41242187499999 6875:-2269.45 6891:-1558.59328125 6978:100.05 6986:-133.51570312500002 6996:81.5325 7027:312.1059375 7030:-238.57273437500004 7058:104.490625 7063:-601.925 7086:-201.40375 7099:-350.38375 7105:-635.0425 7166:65.5725 7170:-337.04375 7189:72.97125 7221:-753.2375 7244:-385.5825 7246:-105.3478125 7250:86.846875 7256:-164.174140625 7319:-55.60875 7320:-2177.49 7323:-1689.32 7355:-1390.545 7362:-433.72679687500005 7364:-3210.745 7366:-704.01125 7371:-441.28375 7405:-2053.828125 7411:-3170.225 7415:-87.09046874999999 7443:-731.5278906249999 7457:-321.73328125 7463:326.2921875 7486:96.50375 7499:-120.10984375000001 7517:93.9525 7523:-315.7925 7524:-285.786171875 7539:-92.297109375 7542:-2814.46875 7549:38.77 7573:-978.9403906249998 7576:61.741625 7595:-418.9725 7611:414.068671875 7619:-91.70578125 7648:143.52375 7662:226.5275 7758:107.21375 7793:-301.0592734375 7820:-2960.4 7878:-2355.53 7880:-3773.97 7893:-113.7375 7934:-2662.495 7946:-73.7521875 7970:-1378.275 8021:-1683.904453125 8027:-102.754171875 8064:-707.10625 8068:-3777.17 8097:-135.615576171875 8104:-712.26875 8125:-1504.87 8146:-811.90875 8153:-508.43875 8227:-306.0975 8232:-658.8375 8233:-123.88218750000001 8235:-254.573046875 8271:-285.29583789062497 8276:406.02789062500005 8277:-226.63146093749998 8279:154.345 8281:-895.145375
current node ID: [6]
pred6.dat = predicted labels file
0.169697 = avg Loss of solution
(56/330) = number of misclassified examples

Printing out global weights after this round of gossip.
[finish]: global weight norm at node[0]: 41046.964161224576
[finish]: global weight norm at node[1]: 24604.391015088477
[finish]: global weight norm at node[2]: 40521.502333544704
[finish]: global weight norm at node[3]: 18642.346990983202
[finish]: global weight norm at node[4]: 39603.36572875622
[finish]: global weight norm at node[5]: 20709.87975766227
[finish]: global weight norm at node[6]: 22096.70866568717
[finish]: global weight norm at node[7]: 14127.90188026453
[finish]: global weight norm at node[8]: 29505.91680478298
[finish]: global weight norm at node[9]: 14223.117902048123
Entering next cycle.
Norm: 14127.90188026453 Node ID: 7
getTrainingData
Loading modelfile
Objective Value after gossip/before training: 2440.19
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_7.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_7.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_7.dat
Objective Value after training: 614.589
WeightVector before pushsum: 
 1809:-1727.58 2192:-1203.89 2701:-2587.35 2838:-3065.82 3080:-4634.07 4762:-1797.54 5066:-1397.07 5881:-2464.3 6253:-2760.15 6720:-2214.66 8021:-3133.2 8097:-4211.52 8271:-748.18
Node 7 is gossiping with Node 9....
WeightVector after pushsum: 
 75:-1141.8049999999998 86:-31.3484375 138:-35.1096875 254:-31.1878125 285:-2359.035 300:79.37718749999999 494:-419.02874999999995 526:-53.9715625 557:-34.0221875 564:79.090125 567:-402.05625 642:-1101.74 672:-336.47562500000004 799:-998.39375 871:757.6775 958:-38.26125 960:165.1165625 969:-107.6540625 971:-45.4590625 1008:-1487.4815624999999 1114:74.695625 1237:-51.560625 1297:-754.80875 1404:-25.924375 1463:-75.3996875 1477:-783.2 1480:-779.1171875 1529:-57.6915625 1533:-554.3775 1643:-193.0896875 1646:328.5125 1694:-264.0475 1725:-578.79859375 1809:-1026.989140625 1826:481.0371875 1827:241.86012499999998 1926:-69.0284375 2051:276.7678125 2054:-228.790625 2112:-51.560625 2125:-1158.7 2192:-1002.122109375 2370:-52.10875 2394:-1567.25 2447:-283.3325 2541:338.796875 2577:-83.60187499999998 2616:-159.7346875 2622:-49.4196875 2656:-316.13184375000003 2701:-1374.5296875 2753:-27.0359375 2828:-1648.1 2838:-1628.71703125 2990:200.55124999999998 3080:-2461.8498437499998 3259:-468.73209375 3438:-37.4934375 3505:-1072.5659375 3549:-95.6996875 3609:-47.321875 3633:-58.2528125 3690:-19.2746875 3780:258.420125 3791:9.236562499999991 3892:-243.943125 3898:-1078.6140625 4023:-160.0421875 4024:-141.1759375 4046:-46.9853125 4142:-70.4990625 4146:-30.8128125 4148:-33.0459375 4155:-35.9096875 4159:202.040625 4227:-60.62125 4251:-85.1871875 4288:160.4165625 4338:-29.631875 4339:-40.845 4435:-67.4746875 4441:-434.13 4472:-1972.6625 4498:364.5415625 4501:155.7540625 4621:250.1575 4624:-1022.8525 4748:-548.875 4762:-1150.62940625 4770:-614.709375 4797:-72.6396875 4800:-41.569375 4802:171.5553125 4820:208.028125 4851:-48.39125 4900:-145.5078125 4918:-1754.5425 5054:-762.19 5066:-742.193359375 5147:-1223.2490625 5191:-26.7709375 5214:350.471875 5219:-34.6415625 5256:-61.3321875 5335:-201.05 5336:-189.2078125 5374:-2030.375 5430:-60.63171875000002 5591:-407.9934375 5675:205.88625 5728:174.87125 5818:-29.1046875 5881:-1383.3920312500002 5888:-46.0409375 5893:111.5690625 5958:-78.36656249999999 6128:171.025625 6131:-54.320625 6179:-43.546875 6224:-35.3034375 6253:-1607.1053125 6450:-338.18006249999996 6514:-47.321875 6574:-30.8128125 6586:82.28346875 6685:-70.4990625 6707:-56.551875 6714:76.057375 6720:-1335.7335156249999 6768:375.065625 6817:-37.0721875 6891:37.111875 6986:-59.3403125 7027:138.71375 7030:-775.1634375000001 7170:-1348.175 7246:-46.82125 7256:-72.9665625 7319:-24.715 7362:-192.7671875 7405:-912.8125 7415:-38.706875 7443:-412.8840625 7457:-38.778125 7463:145.01875 7499:-146.329375 7524:-859.3671875 7539:-41.0209375 7542:-1250.875 7573:-246.6165625 7611:412.99968749999994 7619:-40.758125 7793:-1049.44859375 7893:-50.55 7946:-32.77875 8021:-1831.5578125 8027:-310.7136875 8097:-2648.2223046875 8233:-55.05875 8235:-723.1146875 8271:-533.0443515625 8276:367.2115625 8277:-681.4873437499999
current node ID: [7]
pred7.dat = predicted labels file
0.254545 = avg Loss of solution
(84/330) = number of misclassified examples

Printing out global weights after this round of gossip.
[finish]: global weight norm at node[0]: 41046.964161224576
[finish]: global weight norm at node[1]: 24604.391015088477
[finish]: global weight norm at node[2]: 40521.502333544704
[finish]: global weight norm at node[3]: 18642.346990983202
[finish]: global weight norm at node[4]: 39603.36572875622
[finish]: global weight norm at node[5]: 20709.87975766227
[finish]: global weight norm at node[6]: 22096.70866568717
[finish]: global weight norm at node[7]: 9013.22502030965
[finish]: global weight norm at node[8]: 29505.91680478298
[finish]: global weight norm at node[9]: 9013.22502030965
Entering next cycle.
Norm: 29505.91680478298 Node ID: 8
getTrainingData
Loading modelfile
Objective Value after gossip/before training: 2468.3
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_8.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_8.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_8.dat
Objective Value after training: 628.679
WeightVector before pushsum: 
 149:-1536.93 165:-1237.4 373:-1683.32 407:-624.43 1438:-2808.88 1462:-2012.44 1505:-874.845 1626:-1112.92 1629:-1748.6 1643:-1355.82 1712:-1247.42 1965:-2900.82 2135:-1116.8 2534:-854.545 2570:-1698.45 2616:-728.465 2990:-987.04 3213:-1523.09 3217:-698.1 3296:-1641.72 3436:-1894.37 3456:-2199.64 3791:-737.225 3846:-883.59 4010:-1318.57 4602:-1362.51 4612:-1041.87 5225:-1282.13 5607:-1714.32 5768:-842.05 5801:-862.75 5806:-1293.08 5915:-3275.53 5978:-1044.97 6236:-1546.51 6450:-297.587 6624:-1101.6 6937:-1348.86 7298:-872.39 7323:-1641.11 7443:-675.295 7457:-885.88 7499:-836.525 8027:-425.202 8224:-1023.84
Node 8 is gossiping with Node 4....
WeightVector after pushsum: 
 59:-451.6475 86:-31.3484375 138:-35.1096875 146:-699.455 147:-1548.725 149:-1536.93 165:-1237.4 254:-31.1878125 300:-265.8490625 373:-1683.32 407:-624.43 526:-53.9715625 557:-34.0221875 564:-29.470625 567:-402.05625 672:112.626875 799:-998.39375 871:188.1275 876:-668.7 958:-38.26125 960:165.1165625 969:-107.6540625 971:-45.4590625 1008:-251.3890625 1114:-27.833125 1237:-51.560625 1297:-754.80875 1404:-25.924375 1438:-2808.88 1462:-2012.44 1463:-75.3996875 1480:-32.1596875 1505:-874.845 1516:-204.67 1529:-57.6915625 1533:-426.1 1616:-851.69 1626:-1112.92 1629:-1748.6 1643:-870.9996874999999 1646:328.5125 1694:-264.0475 1712:-1247.42 1725:-23.89109375 1743:-2240.125 1809:-163.19914062499998 1826:227.6421875 1827:164.926875 1926:-69.0284375 1965:-2900.82 2051:276.7678125 2054:-228.790625 2082:-728.54 2112:-51.560625 2125:-1158.7 2135:-1116.8 2155:-7123.25 2192:-252.20910937500003 2279:-406.4325 2314:-409.825 2370:-52.10875 2447:-283.3325 2534:-854.545 2541:338.796875 2546:-486.035 2570:-1698.45 2576:-662.63 2577:245.858125 2597:-489.99 2616:-523.9671875 2622:-49.4196875 2656:-408.82609375000004 2701:-80.8546875 2753:-27.0359375 2838:-95.80703125 2990:-292.96875 3080:-144.81484375 3213:-1523.09 3217:-698.1 3259:-114.97709375 3296:-1641.72 3436:-1894.37 3438:-37.4934375 3456:-2199.64 3505:-63.9684375 3549:-95.6996875 3609:-47.321875 3618:-595.12 3633:-58.2528125 3661:-309.8625 3690:-19.2746875 3780:176.219375 3791:-653.3909375000001 3812:-512.67 3846:-883.59 3892:-243.943125 3897:-4748.365 3898:148.8584375 4010:-1318.57 4023:-160.0421875 4024:-141.1759375 4046:-46.9853125 4142:-70.4990625 4146:-30.8128125 4148:-33.0459375 4155:-35.9096875 4159:202.040625 4227:-60.62125 4251:-85.1871875 4288:160.4165625 4338:-29.631875 4339:-40.845 4435:-67.4746875 4441:-24.1325 4498:155.9703125 4501:-1544.0009375 4602:-1362.51 4612:-1041.87 4621:250.1575 4748:-548.875 4762:-251.85940625 4770:-614.709375 4797:-72.6396875 4800:-41.569375 4802:171.5553125 4820:89.005625 4851:-48.39125 4900:-145.5078125 5066:-43.658359375 5147:-21.6790625 5191:-26.7709375 5201:-499.2 5214:350.471875 5219:-34.6415625 5225:-1282.13 5256:-61.3321875 5292:-13503.8 5310:-748.03 5335:-201.05 5336:-189.2078125 5430:-272.36621875000003 5591:102.5140625 5607:-1714.32 5675:205.88625 5728:174.87125 5768:-842.05 5776:-508.805 5801:-862.75 5806:-1293.08 5818:-29.1046875 5843:-879.64 5881:-151.24203125 5888:-46.0409375 5893:111.5690625 5915:-3275.53 5958:-157.1103125 5978:-1044.97 6128:171.025625 6131:-54.320625 6179:-43.546875 6224:-35.3034375 6235:-363.3225 6236:-1546.51 6253:-227.03031249999998 6329:-1266.75 6387:-856.89 6449:-3872.085 6450:-286.11031249999996 6459:-579.07 6514:-47.321875 6574:-30.8128125 6586:-30.66078125 6596:-387.265 6624:-1101.6 6685:-70.4990625 6707:-56.551875 6714:-28.340625 6720:-228.403515625 6748:-617.795 6768:375.065625 6817:-333.2096875 6839:-819.55 6891:-68.259375 6893:-1262.81 6937:-1348.86 6986:-59.3403125 7027:138.71375 7030:-255.09843750000002 7086:-3297.58 7163:-445.03 7246:-46.82125 7256:-72.9665625 7298:-872.39 7319:-24.715 7323:-1641.11 7362:-192.7671875 7405:-912.8125 7415:-38.706875 7443:-441.9715625 7457:-481.718125 7463:145.01875 7499:-564.591875 7524:-35.4721875 7539:-41.0209375 7542:-1250.875 7573:-1540.9015625 7575:-1036.225 7611:155.4096875 7619:-40.758125 7765:-616.69 7793:-514.3798437500001 7893:-50.55 7898:-724.035 7913:-449.41 7946:-32.77875 8021:-264.9578125 8027:-278.2891875 8097:-126.7123046875 8224:-1023.84 8229:-719.655 8233:-55.05875 8235:-36.8971875 8271:-47.4758515625 8276:157.1128125 8277:-28.12984375 8278:-8602.5
current node ID: [8]
pred8.dat = predicted labels file
0.527273 = avg Loss of solution
(174/330) = number of misclassified examples

Printing out global weights after this round of gossip.
[finish]: global weight norm at node[0]: 41046.964161224576
[finish]: global weight norm at node[1]: 24604.391015088477
[finish]: global weight norm at node[2]: 40521.502333544704
[finish]: global weight norm at node[3]: 18642.346990983202
[finish]: global weight norm at node[4]: 19857.415420298566
[finish]: global weight norm at node[5]: 20709.87975766227
[finish]: global weight norm at node[6]: 22096.70866568717
[finish]: global weight norm at node[7]: 9013.22502030965
[finish]: global weight norm at node[8]: 21957.122237175376
[finish]: global weight norm at node[9]: 9013.22502030965
Entering next cycle.
Norm: 9013.22502030965 Node ID: 9
getTrainingData
Loading modelfile
Objective Value after gossip/before training: 2480.38
Model file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/m_9.dat
Train file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/t_9.dat
Test file: /projects/academic/haimonti/Pegasos4/dsvm/peersim-pegasos/data/reuters/tst_9.dat
Objective Value after training: 634.647
WeightVector before pushsum: 
 75:-1078.48 285:-1983.24 494:-1197.33 642:-2431.7 1008:-917.295 1297:-3840.5 1477:-1566.4 1533:-1108.76 1694:-582.165 2192:-356.303 2394:-3134.5 2828:-3296.2 4472:-1364.24 4624:-2045.7 4762:-322.645 4918:-2456.96 5054:-1524.38 5374:-4060.75 6450:-173.823 7030:-930.83 7170:-2696.35 7793:-1361.89
Node 9 is gossiping with Node 8....
WeightVector after pushsum: 
 59:-225.82375 75:-1078.48 86:-15.67421875 138:-17.55484375 146:-349.7275 147:-774.3625 149:-768.465 165:-618.7 254:-15.59390625 285:-1983.24 300:-132.92453125 373:-841.66 407:-312.215 494:-1197.33 526:-26.98578125 557:-17.01109375 564:-14.7353125 567:-201.028125 642:-2431.7 672:56.3134375 799:-499.196875 871:94.06375 876:-334.35 958:-19.130625 960:82.55828125 969:-53.82703125 971:-22.72953125 1008:-584.34203125 1114:-13.9165625 1237:-25.7803125 1297:-2297.654375 1404:-12.9621875 1438:-1404.44 1462:-1006.22 1463:-37.69984375 1477:-1566.4 1480:-16.07984375 1505:-437.4225 1516:-102.335 1529:-28.84578125 1533:-767.4300000000001 1616:-425.845 1626:-556.46 1629:-874.3 1643:-435.49984374999997 1646:164.25625 1694:-423.10625 1712:-623.71 1725:-11.945546875 1743:-1120.0625 1809:-81.59957031249999 1826:113.82109375 1827:82.4634375 1926:-34.51421875 1965:-1450.41 2051:138.38390625 2054:-114.3953125 2082:-364.27 2112:-25.7803125 2125:-579.35 2135:-558.4 2155:-3561.625 2192:-304.2560546875 2279:-203.21625 2314:-204.9125 2370:-26.054375 2394:-3134.5 2447:-141.66625 2534:-427.2725 2541:169.3984375 2546:-243.0175 2570:-849.225 2576:-331.315 2577:122.9290625 2597:-244.995 2616:-261.98359375 2622:-24.70984375 2656:-204.41304687500002 2701:-40.42734375 2753:-13.51796875 2828:-3296.2 2838:-47.903515625 2990:-146.484375 3080:-72.407421875 3213:-761.545 3217:-349.05 3259:-57.488546875 3296:-820.86 3436:-947.185 3438:-18.74671875 3456:-1099.82 3505:-31.98421875 3549:-47.84984375 3609:-23.6609375 3618:-297.56 3633:-29.12640625 3661:-154.93125 3690:-9.63734375 3780:88.1096875 3791:-326.69546875000003 3812:-256.335 3846:-441.795 3892:-121.9715625 3897:-2374.1825 3898:74.42921875 4010:-659.285 4023:-80.02109375 4024:-70.58796875 4046:-23.49265625 4142:-35.24953125 4146:-15.40640625 4148:-16.52296875 4155:-17.95484375 4159:101.0203125 4227:-30.310625 4251:-42.59359375 4288:80.20828125 4338:-14.8159375 4339:-20.4225 4435:-33.73734375 4441:-12.06625 4472:-1364.24 4498:77.98515625 4501:-772.00046875 4602:-681.255 4612:-520.935 4621:125.07875 4624:-2045.7 4748:-274.4375 4762:-287.252203125 4770:-307.3546875 4797:-36.31984375 4800:-20.7846875 4802:85.77765625 4820:44.5028125 4851:-24.195625 4900:-72.75390625 4918:-2456.96 5054:-1524.38 5066:-21.8291796875 5147:-10.83953125 5191:-13.38546875 5201:-249.6 5214:175.2359375 5219:-17.32078125 5225:-641.065 5256:-30.66609375 5292:-6751.9 5310:-374.015 5335:-100.525 5336:-94.60390625 5374:-4060.75 5430:-136.18310937500002 5591:51.25703125 5607:-857.16 5675:102.943125 5728:87.435625 5768:-421.025 5776:-254.4025 5801:-431.375 5806:-646.54 5818:-14.55234375 5843:-439.82 5881:-75.621015625 5888:-23.02046875 5893:55.78453125 5915:-1637.765 5958:-78.55515625 5978:-522.485 6128:85.5128125 6131:-27.1603125 6179:-21.7734375 6224:-17.65171875 6235:-181.66125 6236:-773.255 6253:-113.51515624999999 6329:-633.375 6387:-428.445 6449:-1936.0425 6450:-229.96665624999997 6459:-289.535 6514:-23.6609375 6574:-15.40640625 6586:-15.330390625 6596:-193.6325 6624:-550.8 6685:-35.24953125 6707:-28.2759375 6714:-14.1703125 6720:-114.2017578125 6748:-308.8975 6768:187.5328125 6817:-166.60484375 6839:-409.775 6891:-34.1296875 6893:-631.405 6937:-674.43 6986:-29.67015625 7027:69.356875 7030:-592.96421875 7086:-1648.79 7163:-222.515 7170:-2696.35 7246:-23.410625 7256:-36.48328125 7298:-436.195 7319:-12.3575 7323:-820.555 7362:-96.38359375 7405:-456.40625 7415:-19.3534375 7443:-220.98578125 7457:-240.8590625 7463:72.509375 7499:-282.2959375 7524:-17.73609375 7539:-20.51046875 7542:-625.4375 7573:-770.45078125 7575:-518.1125 7611:77.70484375 7619:-20.3790625 7765:-308.345 7793:-938.1349218750001 7893:-25.275 7898:-362.0175 7913:-224.705 7946:-16.389375 8021:-132.47890625 8027:-139.14459375 8097:-63.35615234375 8224:-511.92 8229:-359.8275 8233:-27.529375 8235:-18.44859375 8271:-23.73792578125 8276:78.55640625 8277:-14.064921875 8278:-4301.25
current node ID: [9]
pred9.dat = predicted labels file
0.0759878 = avg Loss of solution
(25/329) = number of misclassified examples

Printing out global weights after this round of gossip.
[finish]: global weight norm at node[0]: 41046.964161224576
[finish]: global weight norm at node[1]: 24604.391015088477
[finish]: global weight norm at node[2]: 40521.502333544704
[finish]: global weight norm at node[3]: 18642.346990983202
[finish]: global weight norm at node[4]: 19857.415420298566
[finish]: global weight norm at node[5]: 20709.87975766227
[finish]: global weight norm at node[6]: 22096.70866568717
[finish]: global weight norm at node[7]: 9013.22502030965
[finish]: global weight norm at node[8]: 11314.655207864163
[finish]: global weight norm at node[9]: 14204.73865047674
Running final control
[finish]: global weight norm at node[0]: 41046.964161224576
[finish]: global weight norm at node[1]: 24604.391015088477
[finish]: global weight norm at node[2]: 40521.502333544704
[finish]: global weight norm at node[3]: 18642.346990983202
[finish]: global weight norm at node[4]: 19857.415420298566
[finish]: global weight norm at node[5]: 20709.87975766227
[finish]: global weight norm at node[6]: 22096.70866568717
[finish]: global weight norm at node[7]: 9013.22502030965
[finish]: global weight norm at node[8]: 11314.655207864163
[finish]: global weight norm at node[9]: 14204.73865047674
